{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning on Cassava Leaves Diseases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cassava dataset was shared on Kaggle https://www.kaggle.com/datasets/visalakshiiyer/cassava-image-dataset, disease classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.layers import LeakyReLU, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import datetime \n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 244\n",
    "NUM_CLASSES = 3 # Leaf conditions\n",
    "NUM_CLASSES_SEG = 1 # 0: background, 1: foreground\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the leaf in the image as the region of interest (ROI), I will adapt a custom U-Net model (primarily used in medical applications) to segment the leaf from its background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation parameters\n",
    "data_gen_args = dict(\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to load images from a specified folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img = cv2.imread(os.path.join(folder, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function to create model\n",
    "def create_model(img_shape, num_classes):\n",
    "    inputs = Input(img_shape)\n",
    "\n",
    "    # Encoder (downsampling)\n",
    "    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bridge\n",
    "    bridge = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    bridge = BatchNormalization()(bridge)\n",
    "    bridge = Dropout(0.1)(bridge)\n",
    "\n",
    "    # Decoder (upsampling)\n",
    "    up3 = concatenate([UpSampling2D(size=(2, 2))(bridge), conv2], axis=-1)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Dropout(0.1)(conv3)\n",
    "\n",
    "    up4 = concatenate([UpSampling2D(size=(2, 2))(conv3), conv1], axis=-1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Dropout(0.1)(conv4)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv2D(num_classes, (1, 1), activation='sigmoid')(conv4)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to calculate Dice Coefficient\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "# Function to create mask for plant leaves\n",
    "def create_mask_for_plant(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_hue = np.array([25, 50, 50])\n",
    "    upper_hue = np.array([100, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_hue, upper_hue)\n",
    "    return mask\n",
    "\n",
    "def segment_plant(image):\n",
    "    mask = create_mask_for_plant(image)\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return output\n",
    "\n",
    "def sharpen_image(image):\n",
    "    # Using high-pass filter for image sharpening\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n",
    "    image_sharp = cv2.filter2D(image, -1, kernel)\n",
    "    return image_sharp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaf Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some sample images and visualize\n",
    "sample_folder = './Cassava/brown_streak/'\n",
    "sample_images = load_images_from_folder(sample_folder)\n",
    "\n",
    "# Visualize a sample image\n",
    "plt.imshow(cv2.cvtColor(sample_images[0], cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Sample Original Image\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize a sample mask\n",
    "sample_mask = create_mask_for_plant(sample_images[0])\n",
    "plt.imshow(sample_mask, cmap='viridis')\n",
    "plt.title(\"Sample Mask\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load images from each folder\n",
    "brown_streak = load_images_from_folder('./Cassava/brown_streak/')\n",
    "healthy = load_images_from_folder('./Cassava/healthy1')\n",
    "mosaic_disease = load_images_from_folder('./Cassava/mosaic_disease1')\n",
    "\n",
    "# Concatenate all the images\n",
    "images = brown_streak + healthy + mosaic_disease\n",
    "\n",
    "# Data for plotting\n",
    "data_labels = ['brown_streak']*len(brown_streak) + ['healthy']*len(healthy) + ['mosaic_disease']*len(mosaic_disease)\n",
    "\n",
    "# Create the countplot with the viridis palette\n",
    "sns.countplot(x=data_labels, palette=\"viridis\")\n",
    "\n",
    "# Add a title and labels for better interpretation\n",
    "plt.title('Distribution of Labels in the Dataset', fontsize=16)\n",
    "plt.xlabel('Leaf Condition', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "\n",
    "# Display value counts above bars for clarity\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='baseline', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Resize the images and normalize\n",
    "resized_images = [cv2.resize(image, (IMG_SIZE, IMG_SIZE)) for image in images]\n",
    "\n",
    "# Segment images and create labels\n",
    "labels = []\n",
    "images_segmented = []\n",
    "for image in resized_images:\n",
    "    image_segmented = segment_plant(image)\n",
    "    image_sharpen = sharpen_image(image_segmented)\n",
    "    images_segmented.append(image_sharpen)\n",
    "\n",
    "    image_gray = cv2.cvtColor(image_sharpen, cv2.COLOR_BGR2GRAY)\n",
    "    _, label = cv2.threshold(image_gray, 1, 1, cv2.THRESH_BINARY)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays and adjust types\n",
    "images_segmented = np.array(images_segmented)\n",
    "labels = np.array(labels).astype('float32')\n",
    "\n",
    "# Create a combined labels array\n",
    "combined_labels = [0]*len(brown_streak) + [1]*len(healthy) + [2]*len(mosaic_disease)\n",
    "\n",
    "# Stratified shuffle split for train-val sets\n",
    "stratSplit = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, val_index in stratSplit.split(images_segmented, combined_labels):\n",
    "    x_train, x_val = images_segmented[train_index], images_segmented[val_index]\n",
    "    x_val_original = np.array(resized_images)[val_index] # For visualization \n",
    "    y_train, y_val = labels[train_index], labels[val_index]\n",
    "\n",
    "# Data Augmentation using ImageDataGenerator\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Expand y_train dimensions\n",
    "y_train = np.expand_dims(y_train, -1)\n",
    "\n",
    "# Fit the data generators\n",
    "image_datagen.fit(x_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "# Create the generators\n",
    "image_generator = image_datagen.flow(x_train, batch_size=BATCH_SIZE, seed=seed)\n",
    "mask_generator = mask_datagen.flow(y_train, batch_size=BATCH_SIZE, seed=seed)\n",
    "\n",
    "# Combine generators\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "# Create U-Net model\n",
    "unet_model = create_model((IMG_SIZE, IMG_SIZE, 3), NUM_CLASSES_SEG)\n",
    "\n",
    "# Print the model summary\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Define categories and their corresponding images\n",
    "categories = ['brown_streak', 'healthy', 'mosaic_disease']\n",
    "category_images = [brown_streak, healthy, mosaic_disease]\n",
    "\n",
    "# Create subplots for each category\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Iterate through categories and select one random image per category\n",
    "for i, category in enumerate(categories):\n",
    "    random_image = random.choice(category_images[i])\n",
    "    \n",
    "    # Plot the randomly selected image in the corresponding subplot\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(cv2.cvtColor(random_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display\n",
    "    plt.title(f'Sampled Image ({category})', fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation of U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Initialization ===\n",
      "\n",
      "\n",
      "=== Model Compilation ===\n",
      "\n",
      "\n",
      "=== Model Training ===\n",
      "\n",
      "Epoch 1/50\n",
      "14/13 [===============================] - ETA: -8s - loss: 1.2387 - dice_coef: 0.4292 - accuracy: 0.7574 - precision: 0.3925 - recall: 0.8813\n",
      "Epoch 1: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 199s 15s/step - loss: 1.2387 - dice_coef: 0.4292 - accuracy: 0.7574 - precision: 0.3925 - recall: 0.8813 - val_loss: 6.1403 - val_dice_coef: 0.6566 - val_accuracy: 0.4643 - val_precision: 0.4594 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 1.1017 - dice_coef: 0.4633 - accuracy: 0.8026 - precision: 0.4512 - recall: 0.8660\n",
      "Epoch 2: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 218s 16s/step - loss: 1.1017 - dice_coef: 0.4633 - accuracy: 0.8026 - precision: 0.4512 - recall: 0.8660 - val_loss: 5.6337 - val_dice_coef: 0.6713 - val_accuracy: 0.6050 - val_precision: 0.5354 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.9732 - dice_coef: 0.5123 - accuracy: 0.8305 - precision: 0.5060 - recall: 0.8644\n",
      "Epoch 3: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 233s 17s/step - loss: 0.9732 - dice_coef: 0.5123 - accuracy: 0.8305 - precision: 0.5060 - recall: 0.8644 - val_loss: 5.4735 - val_dice_coef: 0.6673 - val_accuracy: 0.4851 - val_precision: 0.4693 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.9709 - dice_coef: 0.5024 - accuracy: 0.8386 - precision: 0.5048 - recall: 0.8516\n",
      "Epoch 4: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 231s 17s/step - loss: 0.9709 - dice_coef: 0.5024 - accuracy: 0.8386 - precision: 0.5048 - recall: 0.8516 - val_loss: 5.9087 - val_dice_coef: 0.6382 - val_accuracy: 0.4617 - val_precision: 0.4582 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.9041 - dice_coef: 0.5034 - accuracy: 0.8499 - precision: 0.5394 - recall: 0.8187\n",
      "Epoch 5: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 219s 16s/step - loss: 0.9041 - dice_coef: 0.5034 - accuracy: 0.8499 - precision: 0.5394 - recall: 0.8187 - val_loss: 5.0484 - val_dice_coef: 0.6434 - val_accuracy: 0.4665 - val_precision: 0.4604 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.8012 - dice_coef: 0.5836 - accuracy: 0.8666 - precision: 0.5951 - recall: 0.8311\n",
      "Epoch 6: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 222s 17s/step - loss: 0.8012 - dice_coef: 0.5836 - accuracy: 0.8666 - precision: 0.5951 - recall: 0.8311 - val_loss: 4.4859 - val_dice_coef: 0.6381 - val_accuracy: 0.4651 - val_precision: 0.4598 - val_recall: 0.9996 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "14/13 [===============================] - ETA: -10s - loss: 0.8034 - dice_coef: 0.5840 - accuracy: 0.8624 - precision: 0.5929 - recall: 0.7968\n",
      "Epoch 7: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 238s 18s/step - loss: 0.8034 - dice_coef: 0.5840 - accuracy: 0.8624 - precision: 0.5929 - recall: 0.7968 - val_loss: 2.4533 - val_dice_coef: 0.6874 - val_accuracy: 0.5160 - val_precision: 0.4847 - val_recall: 0.9989 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.8064 - dice_coef: 0.5635 - accuracy: 0.8661 - precision: 0.5669 - recall: 0.8115\n",
      "Epoch 8: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 226s 17s/step - loss: 0.8064 - dice_coef: 0.5635 - accuracy: 0.8661 - precision: 0.5669 - recall: 0.8115 - val_loss: 1.2636 - val_dice_coef: 0.7249 - val_accuracy: 0.6126 - val_precision: 0.5409 - val_recall: 0.9856 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.7813 - dice_coef: 0.5631 - accuracy: 0.8743 - precision: 0.6061 - recall: 0.7537\n",
      "Epoch 9: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 227s 17s/step - loss: 0.7813 - dice_coef: 0.5631 - accuracy: 0.8743 - precision: 0.6061 - recall: 0.7537 - val_loss: 0.7686 - val_dice_coef: 0.8070 - val_accuracy: 0.8701 - val_precision: 0.7826 - val_recall: 0.9894 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.7576 - dice_coef: 0.5721 - accuracy: 0.8771 - precision: 0.5953 - recall: 0.7774\n",
      "Epoch 10: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 218s 16s/step - loss: 0.7576 - dice_coef: 0.5721 - accuracy: 0.8771 - precision: 0.5953 - recall: 0.7774 - val_loss: 0.5542 - val_dice_coef: 0.8211 - val_accuracy: 0.8969 - val_precision: 0.8447 - val_recall: 0.9479 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.6886 - dice_coef: 0.6162 - accuracy: 0.8820 - precision: 0.6472 - recall: 0.7763\n",
      "Epoch 11: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 230s 17s/step - loss: 0.6886 - dice_coef: 0.6162 - accuracy: 0.8820 - precision: 0.6472 - recall: 0.7763 - val_loss: 0.4605 - val_dice_coef: 0.8937 - val_accuracy: 0.9316 - val_precision: 0.8838 - val_recall: 0.9783 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.6838 - dice_coef: 0.6198 - accuracy: 0.8883 - precision: 0.6518 - recall: 0.7655\n",
      "Epoch 12: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 227s 17s/step - loss: 0.6838 - dice_coef: 0.6198 - accuracy: 0.8883 - precision: 0.6518 - recall: 0.7655 - val_loss: 0.9511 - val_dice_coef: 0.8157 - val_accuracy: 0.8360 - val_precision: 0.7367 - val_recall: 0.9954 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.6727 - dice_coef: 0.6237 - accuracy: 0.8849 - precision: 0.6530 - recall: 0.7642\n",
      "Epoch 13: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 229s 17s/step - loss: 0.6727 - dice_coef: 0.6237 - accuracy: 0.8849 - precision: 0.6530 - recall: 0.7642 - val_loss: 0.2665 - val_dice_coef: 0.9075 - val_accuracy: 0.9481 - val_precision: 0.9501 - val_recall: 0.9350 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.6778 - dice_coef: 0.6096 - accuracy: 0.8873 - precision: 0.6458 - recall: 0.7695\n",
      "Epoch 14: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 224s 17s/step - loss: 0.6778 - dice_coef: 0.6096 - accuracy: 0.8873 - precision: 0.6458 - recall: 0.7695 - val_loss: 0.2991 - val_dice_coef: 0.8869 - val_accuracy: 0.9275 - val_precision: 0.9711 - val_recall: 0.8666 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.6260 - dice_coef: 0.6445 - accuracy: 0.8893 - precision: 0.6896 - recall: 0.7520\n",
      "Epoch 15: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 226s 17s/step - loss: 0.6260 - dice_coef: 0.6445 - accuracy: 0.8893 - precision: 0.6896 - recall: 0.7520 - val_loss: 0.2270 - val_dice_coef: 0.9245 - val_accuracy: 0.9515 - val_precision: 0.9465 - val_recall: 0.9470 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.6285 - dice_coef: 0.6360 - accuracy: 0.8975 - precision: 0.6838 - recall: 0.7389\n",
      "Epoch 16: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 235s 18s/step - loss: 0.6285 - dice_coef: 0.6360 - accuracy: 0.8975 - precision: 0.6838 - recall: 0.7389 - val_loss: 0.2432 - val_dice_coef: 0.9111 - val_accuracy: 0.9394 - val_precision: 0.9669 - val_recall: 0.8976 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.5687 - dice_coef: 0.6772 - accuracy: 0.9021 - precision: 0.7211 - recall: 0.7712\n",
      "Epoch 17: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 238s 18s/step - loss: 0.5687 - dice_coef: 0.6772 - accuracy: 0.9021 - precision: 0.7211 - recall: 0.7712 - val_loss: 0.5683 - val_dice_coef: 0.7973 - val_accuracy: 0.8548 - val_precision: 0.9946 - val_recall: 0.6848 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.5990 - dice_coef: 0.6561 - accuracy: 0.9015 - precision: 0.6896 - recall: 0.7621\n",
      "Epoch 18: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 219s 17s/step - loss: 0.5990 - dice_coef: 0.6561 - accuracy: 0.9015 - precision: 0.6896 - recall: 0.7621 - val_loss: 0.5641 - val_dice_coef: 0.7895 - val_accuracy: 0.8522 - val_precision: 0.9955 - val_recall: 0.6783 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "14/13 [===============================] - ETA: -9s - loss: 0.6203 - dice_coef: 0.6309 - accuracy: 0.9021 - precision: 0.6798 - recall: 0.7256\n",
      "Epoch 19: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 219s 16s/step - loss: 0.6203 - dice_coef: 0.6309 - accuracy: 0.9021 - precision: 0.6798 - recall: 0.7256 - val_loss: 0.2204 - val_dice_coef: 0.9284 - val_accuracy: 0.9492 - val_precision: 0.9563 - val_recall: 0.9310 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "14/13 [===============================] - ETA: -8s - loss: 0.5534 - dice_coef: 0.6801 - accuracy: 0.9046 - precision: 0.7260 - recall: 0.7641\n",
      "Epoch 20: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 213s 16s/step - loss: 0.5534 - dice_coef: 0.6801 - accuracy: 0.9046 - precision: 0.7260 - recall: 0.7641 - val_loss: 0.2638 - val_dice_coef: 0.9069 - val_accuracy: 0.9317 - val_precision: 0.9805 - val_recall: 0.8673 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "14/13 [===============================] - ETA: -8s - loss: 0.5652 - dice_coef: 0.6701 - accuracy: 0.9064 - precision: 0.7191 - recall: 0.7545\n",
      "Epoch 21: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 212s 16s/step - loss: 0.5652 - dice_coef: 0.6701 - accuracy: 0.9064 - precision: 0.7191 - recall: 0.7545 - val_loss: 0.5301 - val_dice_coef: 0.8331 - val_accuracy: 0.8753 - val_precision: 0.9909 - val_recall: 0.7327 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "14/13 [===============================] - ETA: -8s - loss: 0.5466 - dice_coef: 0.6797 - accuracy: 0.9146 - precision: 0.7292 - recall: 0.7551\n",
      "Epoch 22: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 211s 16s/step - loss: 0.5466 - dice_coef: 0.6797 - accuracy: 0.9146 - precision: 0.7292 - recall: 0.7551 - val_loss: 0.2160 - val_dice_coef: 0.9219 - val_accuracy: 0.9451 - val_precision: 0.9759 - val_recall: 0.9016 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "14/13 [===============================] - ETA: -8s - loss: 0.5369 - dice_coef: 0.6887 - accuracy: 0.9052 - precision: 0.7286 - recall: 0.7733\n",
      "Epoch 23: saving model to unet_best_model.keras\n",
      "13/13 [==============================] - 209s 16s/step - loss: 0.5369 - dice_coef: 0.6887 - accuracy: 0.9052 - precision: 0.7286 - recall: 0.7733 - val_loss: 0.6004 - val_dice_coef: 0.7940 - val_accuracy: 0.8517 - val_precision: 0.9990 - val_recall: 0.6748 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "14/13 [===============================] - ETA: -8s - loss: 0.5695 - dice_coef: 0.6523 - accuracy: 0.9177 - precision: 0.7103 - recall: 0.7260\n",
      "Epoch 24: saving model to unet_best_model.keras\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "13/13 [==============================] - 211s 16s/step - loss: 0.5695 - dice_coef: 0.6523 - accuracy: 0.9177 - precision: 0.7103 - recall: 0.7260 - val_loss: 1.2871 - val_dice_coef: 0.5838 - val_accuracy: 0.7250 - val_precision: 0.9999 - val_recall: 0.3959 - lr: 0.0010\n",
      "Epoch 24: early stopping\n",
      "\n",
      "=== Model Saving and Evaluation ===\n",
      "\n",
      "\n",
      "=== Model Successfully Saved ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# ---------------- Initialization Section ----------------\n",
    "\n",
    "# Debug print model initialization has started\n",
    "print(\"\\n=== Model Initialization ===\\n\")\n",
    "\n",
    "# Setting Callbacks\n",
    "# Logging directory for TensorBoard\n",
    "log_dir = \"logs/fit/unet model\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Initialize TensorBoard, EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau callbacks\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping = EarlyStopping(monitor='val_dice_coef', mode='max', verbose=1, patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('unet_best_model.keras', monitor='val_dice_coef', mode='max',\n",
    "                                    verbose=1, save_weights_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)  # Adjust learning rate\n",
    "\n",
    "# Setting Learning Rate Schedule\n",
    "# Using Exponential Decay for the learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    INITIAL_LEARNING_RATE, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# ---------------- Compilation Section ----------------\n",
    "\n",
    "# Debug print model compilation has started\n",
    "print(\"\\n=== Model Compilation ===\\n\")\n",
    "\n",
    "# Compile the U-Net Model\n",
    "# Metrics include Dice coefficient, accuracy, precision, and recall\n",
    "unet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss=bce_dice_loss,\n",
    "    metrics=[dice_coef, 'accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
    ")\n",
    "\n",
    "# ---------------- Training Section ----------------\n",
    "\n",
    "# Debug print model training has started\n",
    "print(\"\\n=== Model Training ===\\n\")\n",
    "\n",
    "# Train the U-Net Model\n",
    "# Using the data generator for training and validation datasets\n",
    "history = unet_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(x_train) / BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[model_checkpoint, early_stopping, tensorboard_callback, reduce_lr],\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "# ---------------- Post-Training Section ----------------\n",
    "\n",
    "# Debug print model will be saved and evaluated\n",
    "print(\"\\n=== Model Saving and Evaluation ===\\n\")\n",
    "\n",
    "# Save the Trained U-Net Model\n",
    "# Saving the model to disk\n",
    "unet_model.save('trained_unet_model.h5')\n",
    "\n",
    "# Debug print model has been saved successfully\n",
    "print(\"\\n=== Model Successfully Saved ===\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image loading, ROI and cropping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load the UNet model\n",
    "unet_model = tf.keras.models.load_model('trained_unet_model.h5', compile=False)\n",
    "\n",
    "def load_images_and_labels(folders):\n",
    "    \"\"\"\n",
    "    Load original images and labels from the specified folders.\n",
    "    \"\"\"\n",
    "    original_images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each folder to load images\n",
    "    for folder in folders:\n",
    "        standardized_folder = os.path.normpath(folder)\n",
    "        print(f\"Loading images from {standardized_folder}\")  # Debug print\n",
    "        \n",
    "        for filename in os.listdir(standardized_folder):\n",
    "            if filename.endswith('.jpg'):\n",
    "                img = cv2.imread(os.path.join(standardized_folder, filename))\n",
    "                if img is not None:\n",
    "                    original_images.append(img)\n",
    "                    label = standardized_folder.split(os.sep)[-1]\n",
    "                    labels.append(label)\n",
    "                    \n",
    "    print(\"Loaded labels:\", np.unique(labels))  # Debug print\n",
    "    return original_images, labels\n",
    "\n",
    "def find_centre_and_crop(mask, image):\n",
    "    \"\"\"\n",
    "    Find the center of the mask and crop the image around it.\n",
    "    \"\"\"\n",
    "    # Calculate the moments to find the centroid of the mask\n",
    "    M = cv2.moments(mask)\n",
    "    \n",
    "    # If the mask is entirely black, return the original image\n",
    "    if M[\"m00\"] == 0:\n",
    "        return image\n",
    "    \n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "    # Map the center coordinates to the original image dimensions\n",
    "    original_size = image.shape[:2]\n",
    "    cX = int(cX * original_size[1] / IMG_SIZE)\n",
    "    cY = int(cY * original_size[0] / IMG_SIZE)\n",
    "\n",
    "    # Target crop size\n",
    "    target_size = min(original_size) * 87 // 100\n",
    "\n",
    "    top = max(0, cY - target_size // 2)\n",
    "    left = max(0, cX - target_size // 2)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image[top:top + target_size, left:left + target_size]\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess the image to prepare it for prediction.\n",
    "    \"\"\"\n",
    "    resized_image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    resized_image = img_to_array(resized_image)\n",
    "    resized_image = resized_image / 255.0\n",
    "    resized_image = np.expand_dims(resized_image, axis=0)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "def predict_cropped_images(original_images):\n",
    "    \"\"\"\n",
    "    Predict masks and crop the original images based on the masks.\n",
    "    \"\"\"\n",
    "    cropped_images = []\n",
    "    \n",
    "    print(\"Predicting and cropping images...\")  # Debug print\n",
    "    \n",
    "    for image in original_images:\n",
    "        resized_image = preprocess_image(image)\n",
    "        mask = unet_model.predict(resized_image)\n",
    "        mask = np.squeeze(mask, axis=0)\n",
    "        \n",
    "        cropped_image = find_centre_and_crop(mask, image)\n",
    "        cropped_images.append(cropped_image)\n",
    "        \n",
    "    print(\"Prediction and cropping complete.\")  # Debug print\n",
    "    \n",
    "    return cropped_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to display images and overlays\n",
    "def display_samples(predictions, original_images, random_indices, num_samples=5):\n",
    "    \"\"\"Display original and masked images.\n",
    "\n",
    "    Parameters:\n",
    "    predictions (array): The predicted masks from the U-Net model.\n",
    "    original_images (array): The original validation images.\n",
    "    random_indices (array): The indices to sample from the validation set.\n",
    "    num_samples (int): Number of random samples to display.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15, num_samples * 5))\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        # Display original unprocessed image\n",
    "        plt.subplot(num_samples, 2, i * 2 + 1)\n",
    "        plt.imshow(original_images[idx])\n",
    "        plt.title(f\"Sample {i+1}: Original Image\")\n",
    "        \n",
    "        # Create and display a viridis background\n",
    "        plt.subplot(num_samples, 2, i * 2 + 2)\n",
    "        viridis_bg = np.zeros((original_images[idx].shape[0], original_images[idx].shape[1]))\n",
    "        plt.imshow(viridis_bg, cmap='viridis')\n",
    "        \n",
    "        # Overlay the predicted mask on the viridis background\n",
    "        overlay = np.ma.masked_where(predictions[i].squeeze() < 0.5, predictions[i].squeeze())\n",
    "        plt.imshow(overlay, cmap='viridis', alpha=0.6)\n",
    "        plt.title(f\"Sample {i+1}: Mask Overlay\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize U-Net Architecture\n",
    "print(\"Visualizing U-Net Architecture...\")\n",
    "tf.keras.utils.plot_model(unet_model, to_file='unet_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Generate Predictions on Validation Data\n",
    "print(\"Generating predictions on validation data...\")\n",
    "random_indices = np.random.choice(len(x_val), size=5, replace=False)  # 5 random samples\n",
    "predictions = unet_model.predict(x_val[random_indices])\n",
    "\n",
    "# Display Random Sample Input Images and Their Corresponding Masks\n",
    "print(\"Displaying random sample input images and their corresponding masks...\")\n",
    "display_samples(predictions, x_val_original, random_indices)\n",
    "\n",
    "print(\"Visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load images and labels...\n",
      "Loading images from Cassava\\brown_streak\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Images and labels loaded successfully.\n",
      "Starting to predict and crop images...\n",
      "Predicting and cropping images...\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Prediction and cropping complete.\n",
      "Prediction and cropping completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # Required for plotting\n",
    "\n",
    "# Load all images and labels from specified directories\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "try:\n",
    "    print(\"Starting to load images and labels...\")  # Debug print\n",
    "    original_images, labels = load_images_and_labels(folders)\n",
    "    print(\"Images and labels loaded successfully.\")  # Debug print\n",
    "    \n",
    "    print(\"Starting to predict and crop images...\")  # Debug print\n",
    "    cropped_images = predict_cropped_images(original_images)\n",
    "    print(\"Prediction and cropping completed successfully.\")  # Debug print\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")  # Error message\n",
    "    cropped_images = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of random samples to display\n",
    "num_samples = 5\n",
    "\n",
    "# Randomly select indices for display\n",
    "print(\"Randomly selecting images for display...\")  # Debug print\n",
    "random_indices = np.random.choice(len(original_images), size=num_samples - 1, replace=False)\n",
    "\n",
    "# Add 497 to the random indices, ensuring it's always sampled (cassava stem)\n",
    "random_indices = np.append(random_indices, 497)\n",
    "\n",
    "# Initialize the plotting area\n",
    "plt.figure(figsize=(15, num_samples * 5))\n",
    "\n",
    "# Iterate through each randomly selected index\n",
    "for i, idx in enumerate(random_indices):\n",
    "    # Display original image\n",
    "    plt.subplot(num_samples, 2, i * 2 + 1)\n",
    "    plt.imshow(cv2.cvtColor(original_images[idx], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Original Image: {labels[idx]}\")\n",
    "    \n",
    "    # Display the corresponding cropped image\n",
    "    plt.subplot(num_samples, 2, i * 2 + 2)\n",
    "    plt.imshow(cv2.cvtColor(cropped_images[idx], cv2.COLOR_BGR2RGB), cmap='viridis')\n",
    "    plt.title(f\"Cropped (ROI) Image: {labels[idx]}\")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Displaying the selected original and cropped images.\")  # Debug print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of random samples to display\n",
    "num_samples = 10\n",
    "\n",
    "# Randomly select indices for display\n",
    "print(\"Randomly selecting images for display...\")  # Debug print\n",
    "random_indices = np.random.choice(len(original_images), size=num_samples, replace=False)\n",
    "\n",
    "# Initialize the plotting area\n",
    "plt.figure(figsize=(15, num_samples * 5))\n",
    "\n",
    "# Iterate through each randomly selected index\n",
    "for i, idx in enumerate(random_indices):\n",
    "    # Display original image\n",
    "    plt.subplot(num_samples, 2, i * 2 + 1)\n",
    "    plt.imshow(cv2.cvtColor(original_images[idx], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Original Image: {labels[idx]}\")\n",
    "    \n",
    "    # Display the corresponding cropped image\n",
    "    plt.subplot(num_samples, 2, i * 2 + 2)\n",
    "    plt.imshow(cv2.cvtColor(cropped_images[idx], cv2.COLOR_BGR2RGB), cmap='viridis')\n",
    "    plt.title(f\"Cropped (ROI) Image: {labels[idx]}\")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Displaying the selected original and cropped images.\")  # Debug print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple CNN to establish baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and cropping images...\n",
      "Loading images from Cassava\\brown_streak\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Predicting and cropping images...\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Prediction and cropping complete.\n",
      "Preprocessing images...\n",
      "Encoding labels...\n",
      "Splitting dataset...\n",
      "Defining model architecture...\n",
      "Compiling model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 242, 242, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 121, 121, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 119, 119, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 59, 59, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 57, 57, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 28, 28, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               51380736  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51475523 (196.36 MB)\n",
      "Trainable params: 51475523 (196.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Starting model training...\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 51s 4s/step - loss: 2.6426 - accuracy: 0.5841 - val_loss: 0.9074 - val_accuracy: 0.6111\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.7807 - accuracy: 0.6752 - val_loss: 0.7158 - val_accuracy: 0.7037\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.6301 - accuracy: 0.7266 - val_loss: 0.5989 - val_accuracy: 0.7778\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.4958 - accuracy: 0.7921 - val_loss: 0.4700 - val_accuracy: 0.7778\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.3916 - accuracy: 0.8224 - val_loss: 0.3800 - val_accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.3307 - accuracy: 0.8785 - val_loss: 0.4016 - val_accuracy: 0.8148\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.3186 - accuracy: 0.9042 - val_loss: 0.3670 - val_accuracy: 0.8148\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.2171 - accuracy: 0.9159 - val_loss: 0.5185 - val_accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.2430 - accuracy: 0.9252 - val_loss: 0.3862 - val_accuracy: 0.8148\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.2170 - accuracy: 0.8995 - val_loss: 0.3925 - val_accuracy: 0.8241\n",
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import numpy as np  # If not already imported and loading u-net model\n",
    "import cv2  # If not already imported and loading u-net model\n",
    "\n",
    "# Load and crop images\n",
    "print(\"Loading and cropping images...\")  # Debug print\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "cropped_images = predict_cropped_images(original_images)\n",
    "\n",
    "# Preprocess images for model training\n",
    "print(\"Preprocessing images...\")  # Debug print\n",
    "cropped_images_array = np.array([cv2.resize(img, (IMG_SIZE, IMG_SIZE)) for img in cropped_images]) / 255.0\n",
    "\n",
    "# Encode labels into integers and then into one-hot encoding\n",
    "print(\"Encoding labels...\")  # Debug print\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "print(\"Splitting dataset...\")  # Debug print\n",
    "X_train, X_val, y_train, y_val = train_test_split(cropped_images_array, categorical_labels, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Define the Convolutional Neural Network (CNN) model architecture\n",
    "print(\"Defining model architecture...\")  # Debug print\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "print(\"Compiling model...\")  # Debug print\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Set up TensorBoard for real-time performance monitoring\n",
    "log_dir = \"logs/fit/seq cnn simple \" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the CNN model\n",
    "print(\"Starting model training...\")  # Debug print\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[tensorboard_callback])\n",
    "print(\"Model training completed.\")  # Debug print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Evaluation Section ----\n",
    "\n",
    "print(\"\\n=== Model Evaluation ===\\n\")\n",
    "\n",
    "# Evaluate Model on Validation Data\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Generate and Display Confusion Matrix\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to label index\n",
    "y_true_classes = np.argmax(y_val, axis=1)  # Convert one-hot encoded ground truth to label index\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Generate and Display Classification Report\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# ---- Visualization Section ----\n",
    "\n",
    "print(\"\\n=== Training and Validation Curves ===\\n\")\n",
    "\n",
    "# Initialize Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot Accuracy Curves\n",
    "axes[0].plot(history.history['accuracy'], 'b--', marker='o', label='Training Accuracy', color='b') \n",
    "axes[0].plot(history.history['val_accuracy'], 'r-', marker='x', label='Validation Accuracy', color='r') \n",
    "\n",
    "axes[0].set_title('Training vs Validation Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot Loss Curves\n",
    "axes[1].plot(history.history['loss'], 'g--', marker='o', label='Training Loss', color='g')  \n",
    "axes[1].plot(history.history['val_loss'], 'm-', marker='x', label='Validation Loss', color='m')  \n",
    "\n",
    "axes[1].set_title('Training vs Validation Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model initially struggles to perform well on training and validation data but gradually improves. Whilst initially promising with an accuracy of 82%, further inspection shows the brown streak disease has an F1-score of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition of balanced class weights to address the class imbalance and boost the F1-score for the brown streak disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and cropping images...\n",
      "Loading images from Cassava\\brown_streak\n",
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Predicting and cropping images...\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Prediction and cropping complete.\n",
      "Preparing images for training...\n",
      "Encoding labels...\n",
      "Splitting dataset into training and validation sets...\n",
      "Defining the CNN model...\n",
      "Computing class weights...\n",
      "Compiling and training the model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 242, 242, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 121, 121, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 119, 119, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 59, 59, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 57, 57, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 28, 28, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 100352)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               51380736  \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51475523 (196.36 MB)\n",
      "Trainable params: 51475523 (196.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 2.6057 - accuracy: 0.4650 - val_loss: 0.8563 - val_accuracy: 0.7130\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.0210 - accuracy: 0.4883 - val_loss: 0.9996 - val_accuracy: 0.3148\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.9815 - accuracy: 0.5093 - val_loss: 0.6435 - val_accuracy: 0.7130\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.8625 - accuracy: 0.6682 - val_loss: 1.0394 - val_accuracy: 0.5463\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.7543 - accuracy: 0.6776 - val_loss: 0.6892 - val_accuracy: 0.7407\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.7711 - accuracy: 0.6612 - val_loss: 0.8882 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.6507 - accuracy: 0.7757 - val_loss: 0.7269 - val_accuracy: 0.5463\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.5705 - accuracy: 0.7944 - val_loss: 0.7083 - val_accuracy: 0.7407\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.5515 - accuracy: 0.7687 - val_loss: 0.5603 - val_accuracy: 0.8056\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.3972 - accuracy: 0.8668 - val_loss: 0.7660 - val_accuracy: 0.5926\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ---- Load Data ----\n",
    "# Load and crop images from specified folders\n",
    "print(\"Loading and cropping images...\")\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "cropped_images = predict_cropped_images(original_images)\n",
    "\n",
    "# Convert cropped images into a numpy array suitable for training\n",
    "print(\"Preparing images for training...\")\n",
    "cropped_images_array = np.array([cv2.resize(img, (IMG_SIZE, IMG_SIZE)) for img in cropped_images]) / 255.0\n",
    "\n",
    "# ---- Preprocessing ----\n",
    "# Encode labels to integers and then to categorical format\n",
    "print(\"Encoding labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Split the dataset into training and validation sets with stratification\n",
    "print(\"Splitting dataset into training and validation sets...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    cropped_images_array, categorical_labels, test_size=0.2, \n",
    "    random_state=seed, stratify=categorical_labels)\n",
    "\n",
    "# ---- Model Definition ----\n",
    "# Define the architecture of the Convolutional Neural Network (CNN)\n",
    "print(\"Defining the CNN model...\")\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "print(\"Computing class weights...\")\n",
    "class_weights = compute_class_weight(class_weight='balanced', \n",
    "                                     classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Compile and train the model\n",
    "print(\"Compiling and training the model...\")\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Define TensorBoard callback for real-time performance monitoring\n",
    "log_dir = \"logs/fit/seq cnn plus + class weights \" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), epochs=10, \n",
    "    callbacks=[tensorboard_callback], class_weight=class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Evaluation Section ----\n",
    "\n",
    "print(\"\\n=== Model Evaluation ===\\n\")\n",
    "\n",
    "# Evaluate Model on Validation Data\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Generate and Display Confusion Matrix\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to label index\n",
    "y_true_classes = np.argmax(y_val, axis=1)  # Convert one-hot encoded ground truth to label index\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Generate and Display Classification Report\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# ---- Visualization Section ----\n",
    "\n",
    "print(\"\\n=== Training and Validation Curves ===\\n\")\n",
    "\n",
    "# Initialize Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot Accuracy Curves\n",
    "axes[0].plot(history.history['accuracy'], 'b--', marker='o', label='Training Accuracy', color='b') \n",
    "axes[0].plot(history.history['val_accuracy'], 'r-', marker='x', label='Validation Accuracy', color='r') \n",
    "\n",
    "axes[0].set_title('Training vs Validation Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot Loss Curves\n",
    "axes[1].plot(history.history['loss'], 'g--', marker='o', label='Training Loss', color='g')  \n",
    "axes[1].plot(history.history['val_loss'], 'm-', marker='x', label='Validation Loss', color='m')  \n",
    "\n",
    "axes[1].set_title('Training vs Validation Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though overall accuracy is down to 59%, the smallest class (brown streak disease) sees an improved F1 Score of 35%, and the persistent gaps between training and validation accuracies suggest overfitting, highlighting the need for further optimization to enhance generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified K-Fold Cross-Validation is used with the current CNN to maximise all the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import cv2  \n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Define function to plot metrics\n",
    "def plot_metrics(metrics, metric_name):\n",
    "    labels = list(metrics.keys())\n",
    "    values = [np.mean(metrics[label]) for label in labels]\n",
    "    \n",
    "    # Generate colors from viridis colormap within the range [4/4.5, 4.5/7]\n",
    "    colormap = cm.viridis(np.linspace(4/4.5, 4.5/7, len(labels)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(labels, values, color=colormap)  # Use colors from the adjusted viridis colormap\n",
    "    plt.xlabel(metric_name)\n",
    "    plt.ylabel('Class Labels')\n",
    "    plt.title(f'Average {metric_name} for Each Class')\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(v, i, str(round(v, 2)), va='center', ha=\"left\")\n",
    "    plt.show()\n",
    "\n",
    "# Initialize metrics dictionary for precision, recall, F1 score, and accuracy\n",
    "class_metrics = {'precision': {}, 'recall': {}, 'f1-score': {}, 'accuracy': {}}\n",
    "\n",
    "# Loading and preprocessing images\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "cropped_images = predict_cropped_images(original_images)\n",
    "cropped_images_array = np.array([cv2.resize(img, (IMG_SIZE, IMG_SIZE)) for img in cropped_images])\n",
    "\n",
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# K-Folds Cross-Validation setup\n",
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "confusion_matrices = []\n",
    "\n",
    "# K-Fold Cross-Validation loop\n",
    "for train_index, val_index in stratified_k_fold.split(cropped_images_array, encoded_labels):\n",
    "\n",
    "    X_train, X_test = cropped_images_array[train_index], cropped_images_array[val_index]\n",
    "    y_train, y_test = categorical_labels[train_index], categorical_labels[val_index]\n",
    "\n",
    "    # CNN model definition\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    log_dir = \"logs/cnn + weights n kfold\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, class_weight=class_weight_dict,\n",
    "               callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Model evaluation and metrics calculation\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "    report = classification_report(y_true_classes, y_pred_classes, output_dict=True, zero_division=1)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    confusion_matrices.append(cnf_matrix)\n",
    "\n",
    "    for lbl in label_encoder.classes_:\n",
    "        class_idx = label_encoder.transform([lbl])[0]\n",
    "        class_metrics['precision'][lbl] = class_metrics['precision'].get(lbl, []) + [report[str(class_idx)]['precision']]\n",
    "        class_metrics['recall'][lbl] = class_metrics['recall'].get(lbl, []) + [report[str(class_idx)]['recall']]\n",
    "        class_metrics['f1-score'][lbl] = class_metrics['f1-score'].get(lbl, []) + [report[str(class_idx)]['f1-score']]\n",
    "        class_metrics['accuracy'][lbl] = class_metrics['accuracy'].get(lbl, []) + [accuracy_score(y_true_classes[y_true_classes==class_idx],\n",
    "                                                                                                                           y_pred_classes[y_true_classes==class_idx])]\n",
    "\n",
    "# Averaging the metrics\n",
    "for metric, class_data in class_metrics.items():\n",
    "    for lbl, values in class_data.items():\n",
    "        class_metrics[metric][lbl] = np.mean(values)\n",
    "\n",
    "# Visualizing the metrics\n",
    "for metric_name in ['f1-score', 'accuracy']:\n",
    "    plot_metrics(class_metrics[metric_name], metric_name)\n",
    "\n",
    "# Sample three images from each class/label\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for lbl in label_encoder.classes_:\n",
    "    class_idx = label_encoder.transform([lbl])[0]\n",
    "    indices = np.where(np.array(y_true_classes) == class_idx)[0][:3]  # Sample three images per class\n",
    "    sample_images.extend(X_test[indices])\n",
    "    sample_labels.extend([lbl] * 3)\n",
    "\n",
    "# Generate predictions for the sampled images\n",
    "sample_predictions = model.predict(np.array(sample_images))\n",
    "sample_predictions = np.argmax(sample_predictions, axis=1)\n",
    "\n",
    "# Decode the true and predicted labels to their original string labels\n",
    "decoded_true_labels = label_encoder.inverse_transform([label_encoder.transform([lbl])[0] for lbl in sample_labels])\n",
    "decoded_predicted_labels = label_encoder.inverse_transform(sample_predictions)\n",
    "\n",
    "# Plot the sampled images along with their true and predicted labels\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"True: {decoded_true_labels[i]}\\nPred: {decoded_predicted_labels[i]}\", fontsize=10)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Stratified K-Fold Cross-Validation had varying performance levels across different leaf conditions. It performed relatively well for \"healthy\" leaves, with a high average F1 score and accuracy. The \"mosaic disease\" class showed a reasonable F1 score and accuracy. However, the \"brown streak\" class had lower F1-score and accuracy values, indicating that the model had more difficulty classifying this condition accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation to mitigate and improve the F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cassava\\brown_streak\n",
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 34s 2s/step - loss: 1.9210 - accuracy: 0.4182 - val_loss: 1.1546 - val_accuracy: 0.2778\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.9133 - accuracy: 0.5070 - val_loss: 0.9955 - val_accuracy: 0.5463\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.7343 - accuracy: 0.5981 - val_loss: 1.2468 - val_accuracy: 0.6204\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.8144 - accuracy: 0.5467 - val_loss: 0.8014 - val_accuracy: 0.6389\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.5883 - accuracy: 0.7266 - val_loss: 0.5555 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.5485 - accuracy: 0.7033 - val_loss: 0.6026 - val_accuracy: 0.6759\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.4308 - accuracy: 0.7547 - val_loss: 0.2414 - val_accuracy: 0.8796\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.3970 - accuracy: 0.7874 - val_loss: 0.6559 - val_accuracy: 0.7870\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.4333 - accuracy: 0.7850 - val_loss: 0.2697 - val_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.4364 - accuracy: 0.7360 - val_loss: 0.3133 - val_accuracy: 0.8611\n",
      "4/4 [==============================] - 1s 152ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 2.3007 - accuracy: 0.3566 - val_loss: 0.9247 - val_accuracy: 0.5421\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0202 - accuracy: 0.5198 - val_loss: 0.7821 - val_accuracy: 0.6822\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8971 - accuracy: 0.4965 - val_loss: 0.9338 - val_accuracy: 0.3738\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9308 - accuracy: 0.3753 - val_loss: 0.8402 - val_accuracy: 0.5421\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.6975 - accuracy: 0.6084 - val_loss: 0.4431 - val_accuracy: 0.8037\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.6142 - accuracy: 0.6737 - val_loss: 0.3214 - val_accuracy: 0.8598\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7375 - accuracy: 0.4709 - val_loss: 0.6862 - val_accuracy: 0.6168\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.5907 - accuracy: 0.7063 - val_loss: 0.3476 - val_accuracy: 0.8598\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.4314 - accuracy: 0.7716 - val_loss: 0.4288 - val_accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.3613 - accuracy: 0.7925 - val_loss: 0.4517 - val_accuracy: 0.8505\n",
      "4/4 [==============================] - 1s 132ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.6529 - accuracy: 0.4452 - val_loss: 0.7662 - val_accuracy: 0.6636\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8642 - accuracy: 0.4942 - val_loss: 0.7924 - val_accuracy: 0.6822\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7243 - accuracy: 0.6247 - val_loss: 0.6464 - val_accuracy: 0.7664\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.5045 - accuracy: 0.7413 - val_loss: 1.3940 - val_accuracy: 0.6449\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.5252 - accuracy: 0.7366 - val_loss: 0.4865 - val_accuracy: 0.8131\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 14s 1s/step - loss: 0.5639 - accuracy: 0.7319 - val_loss: 0.4527 - val_accuracy: 0.8318\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.4961 - accuracy: 0.7319 - val_loss: 0.8372 - val_accuracy: 0.7383\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 14s 1s/step - loss: 0.5011 - accuracy: 0.7273 - val_loss: 0.6272 - val_accuracy: 0.7103\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.3594 - accuracy: 0.8019 - val_loss: 0.5224 - val_accuracy: 0.8411\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.4237 - accuracy: 0.7436 - val_loss: 0.4216 - val_accuracy: 0.8318\n",
      "4/4 [==============================] - 1s 130ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 2.5004 - accuracy: 0.4895 - val_loss: 0.9262 - val_accuracy: 0.6636\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.9568 - accuracy: 0.5105 - val_loss: 0.5846 - val_accuracy: 0.7570\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.7999 - accuracy: 0.5711 - val_loss: 0.6493 - val_accuracy: 0.6822\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.7596 - accuracy: 0.5524 - val_loss: 0.4489 - val_accuracy: 0.8598\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.6401 - accuracy: 0.6480 - val_loss: 0.4411 - val_accuracy: 0.8318\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.6017 - accuracy: 0.6667 - val_loss: 0.4449 - val_accuracy: 0.7757\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.4663 - accuracy: 0.7902 - val_loss: 0.2481 - val_accuracy: 0.9065\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.5079 - accuracy: 0.7599 - val_loss: 1.2703 - val_accuracy: 0.5421\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8034 - accuracy: 0.4336 - val_loss: 0.6553 - val_accuracy: 0.6168\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.6823 - accuracy: 0.7016 - val_loss: 0.3285 - val_accuracy: 0.8598\n",
      "4/4 [==============================] - 1s 133ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 2.2328 - accuracy: 0.4056 - val_loss: 0.8568 - val_accuracy: 0.4953\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7796 - accuracy: 0.5967 - val_loss: 0.4730 - val_accuracy: 0.8037\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.6893 - accuracy: 0.6480 - val_loss: 0.6258 - val_accuracy: 0.6355\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.6073 - accuracy: 0.6364 - val_loss: 0.7364 - val_accuracy: 0.5701\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 14s 1s/step - loss: 0.5512 - accuracy: 0.7040 - val_loss: 0.5990 - val_accuracy: 0.6916\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.5626 - accuracy: 0.6783 - val_loss: 0.5580 - val_accuracy: 0.7383\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.5303 - accuracy: 0.6923 - val_loss: 0.4006 - val_accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.4545 - accuracy: 0.7459 - val_loss: 0.3718 - val_accuracy: 0.8131\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 14s 1s/step - loss: 0.4552 - accuracy: 0.7319 - val_loss: 0.2583 - val_accuracy: 0.8879\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.4039 - accuracy: 0.7622 - val_loss: 0.4678 - val_accuracy: 0.8037\n",
      "4/4 [==============================] - 1s 133ms/step\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Load and crop images\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "\n",
    "# Convert cropped images into a format suitable for training\n",
    "cropped_images_array = np.array([cv2.resize(img, (224, 224)) for img in original_images]) / 255.0\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create a data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Compute confusion matrices for each class\n",
    "confusion_matrices = []\n",
    "\n",
    "# Initialize metrics dictionary for precision, recall, F1 score, and accuracy\n",
    "class_metrics = {'precision': {}, 'recall': {}, 'f1-score': {}, 'accuracy': {}}\n",
    "\n",
    "# K-Fold Cross-Validation loop\n",
    "for train_index, val_index in stratified_k_fold.split(cropped_images_array, encoded_labels):\n",
    "    \n",
    "    X_train, X_val = cropped_images_array[train_index], cropped_images_array[val_index]\n",
    "    y_train, y_val = categorical_labels[train_index], categorical_labels[val_index]\n",
    "    \n",
    "    # Create data generator for the training set\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "    \n",
    "    # Define the CNN model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define TensorBoard callback\n",
    "    log_dir = \"logs/fit/ CNN with augmentation\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Fit the model using the data generator\n",
    "    history = model.fit(train_generator, validation_data=(X_val, y_val), epochs=10, callbacks=[tensorboard_callback],\n",
    "                         class_weight=class_weight_dict)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Compute confusion matrix and add to the list\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "    confusion_matrices.append(cnf_matrix)\n",
    "\n",
    "    # Calculate and accumulate the metrics\n",
    "    report = classification_report(y_true, y_pred_classes, output_dict=True, zero_division=1)\n",
    "\n",
    "    for lbl in label_encoder.classes_:\n",
    "        class_idx = label_encoder.transform([lbl])[0]\n",
    "        class_metrics['precision'][lbl] = class_metrics['precision'].get(lbl, []) + [report[str(class_idx)]['precision']]\n",
    "        class_metrics['recall'][lbl] = class_metrics['recall'].get(lbl, []) + [report[str(class_idx)]['recall']]\n",
    "        class_metrics['f1-score'][lbl] = class_metrics['f1-score'].get(lbl, []) + [report[str(class_idx)]['f1-score']]\n",
    "        class_metrics['accuracy'][lbl] = class_metrics['accuracy'].get(lbl, []) + [accuracy_score(y_true[y_true==class_idx], \n",
    "                                                                                                  y_pred_classes[y_true==class_idx])]\n",
    "    \n",
    "    # Compute confusion matrix and add to the list\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "    confusion_matrices.append(cnf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the metrics\n",
    "for metric, class_data in class_metrics.items():\n",
    "    for lbl, values in class_data.items():\n",
    "        class_metrics[metric][lbl] = np.mean(values)\n",
    "\n",
    "# Visualizing the metrics\n",
    "for metric_name in ['f1-score', 'accuracy']:\n",
    "    plot_metrics(class_metrics[metric_name], metric_name)\n",
    "\n",
    "# Sample three images from each class/label\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for lbl in label_encoder.classes_:\n",
    "    class_idx = label_encoder.transform([lbl])[0]\n",
    "    indices = np.where(np.array(y_true) == class_idx)[0][:3]  # Sample three images per class\n",
    "    sample_images.extend(X_test[indices])\n",
    "    sample_labels.extend([lbl] * 3)\n",
    "\n",
    "# Resize sampled images to match the model's input shape\n",
    "sample_images_resized = [cv2.resize(img, (224, 224)) for img in sample_images]\n",
    "\n",
    "# Generate predictions for the sampled images\n",
    "sample_predictions = model.predict(np.array(sample_images_resized))\n",
    "sample_predictions = np.argmax(sample_predictions, axis=1)\n",
    "\n",
    "# Decode the true and predicted labels to their original string labels\n",
    "decoded_true_labels = label_encoder.inverse_transform([label_encoder.transform([lbl])[0] for lbl in sample_labels])\n",
    "decoded_predicted_labels = label_encoder.inverse_transform(sample_predictions)\n",
    "\n",
    "# Plot the sampled images along with their true and predicted labels\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"True: {decoded_true_labels[i]}\\nPred: {decoded_predicted_labels[i]}\", fontsize=10)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying data augmentation techniques, the model's performance significantly improved across all three classes. For mosaic diseases and healthy leaf conditions, both F1-score and accuracy substantially increased, indicating a better ability to classify these conditions. However, for the brown streak, this class remains challenging for the model even after augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with SMOTE and adjusted decision threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus is to address the regression observed in the previous model; a lowered decision threshold alongside applying SMOTE to the CNN may reverse and improve the F1-score of the underrepresented class, brown streak disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cassava\\brown_streak\n",
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 37s 1s/step - loss: 3.0905 - accuracy: 0.4453 - val_loss: 1.3336 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.7457 - accuracy: 0.6468 - val_loss: 0.6162 - val_accuracy: 0.7315\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.5293 - accuracy: 0.7500 - val_loss: 0.5267 - val_accuracy: 0.8426\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.6808 - accuracy: 0.7388 - val_loss: 1.8498 - val_accuracy: 0.3796\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.4982 - accuracy: 0.7836 - val_loss: 0.7724 - val_accuracy: 0.7407\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.5296 - accuracy: 0.7749 - val_loss: 0.3978 - val_accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.4360 - accuracy: 0.8035 - val_loss: 0.8303 - val_accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.3775 - accuracy: 0.8358 - val_loss: 0.4478 - val_accuracy: 0.8611\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.3133 - accuracy: 0.8619 - val_loss: 0.9462 - val_accuracy: 0.8611\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.4478 - accuracy: 0.8458 - val_loss: 0.4734 - val_accuracy: 0.8519\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000151278ACEA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 1s 147ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 2.1446 - accuracy: 0.4895 - val_loss: 1.4191 - val_accuracy: 0.3364\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.8395 - accuracy: 0.6493 - val_loss: 0.7266 - val_accuracy: 0.7477\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.5374 - accuracy: 0.7584 - val_loss: 1.6120 - val_accuracy: 0.5701\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.4192 - accuracy: 0.8030 - val_loss: 1.0863 - val_accuracy: 0.7290\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.3443 - accuracy: 0.8563 - val_loss: 0.5515 - val_accuracy: 0.8037\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 40s 2s/step - loss: 0.3895 - accuracy: 0.8302 - val_loss: 0.3434 - val_accuracy: 0.8411\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 37s 1s/step - loss: 0.3813 - accuracy: 0.8538 - val_loss: 0.3637 - val_accuracy: 0.8411\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 37s 1s/step - loss: 0.3314 - accuracy: 0.8686 - val_loss: 0.9198 - val_accuracy: 0.7196\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.2753 - accuracy: 0.8736 - val_loss: 0.5563 - val_accuracy: 0.8505\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.3148 - accuracy: 0.8686 - val_loss: 0.6559 - val_accuracy: 0.7383\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001510F3093A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 1s 184ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 44s 2s/step - loss: 1.7102 - accuracy: 0.5824 - val_loss: 1.0708 - val_accuracy: 0.5140\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4831 - accuracy: 0.7509 - val_loss: 0.4332 - val_accuracy: 0.8224\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 26s 988ms/step - loss: 0.3601 - accuracy: 0.8315 - val_loss: 0.5413 - val_accuracy: 0.8598\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.4431 - accuracy: 0.7968 - val_loss: 2.1271 - val_accuracy: 0.5888\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 26s 1s/step - loss: 0.4854 - accuracy: 0.7993 - val_loss: 0.3478 - val_accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.4510 - accuracy: 0.8104 - val_loss: 0.8547 - val_accuracy: 0.5981\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.4379 - accuracy: 0.8401 - val_loss: 1.8179 - val_accuracy: 0.6916\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.3533 - accuracy: 0.8463 - val_loss: 0.3581 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 26s 1s/step - loss: 0.2701 - accuracy: 0.8860 - val_loss: 0.3046 - val_accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 26s 1000ms/step - loss: 0.3863 - accuracy: 0.8451 - val_loss: 0.6004 - val_accuracy: 0.8224\n",
      "4/4 [==============================] - 1s 137ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 2.5398 - accuracy: 0.5477 - val_loss: 1.3668 - val_accuracy: 0.3645\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.6582 - accuracy: 0.6914 - val_loss: 0.7865 - val_accuracy: 0.6355\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.6559 - accuracy: 0.7373 - val_loss: 0.4490 - val_accuracy: 0.8224\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 26s 976ms/step - loss: 0.4928 - accuracy: 0.8042 - val_loss: 0.9108 - val_accuracy: 0.6916\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 24s 936ms/step - loss: 0.3972 - accuracy: 0.8104 - val_loss: 0.3995 - val_accuracy: 0.8598\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.3124 - accuracy: 0.8563 - val_loss: 1.4002 - val_accuracy: 0.7009\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 26s 978ms/step - loss: 0.5078 - accuracy: 0.7881 - val_loss: 0.4052 - val_accuracy: 0.8411\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.3344 - accuracy: 0.8401 - val_loss: 0.3518 - val_accuracy: 0.9065\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.3136 - accuracy: 0.8699 - val_loss: 0.4689 - val_accuracy: 0.8411\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.3045 - accuracy: 0.8476 - val_loss: 0.4605 - val_accuracy: 0.8411\n",
      "4/4 [==============================] - 1s 142ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 2.2136 - accuracy: 0.5192 - val_loss: 0.9192 - val_accuracy: 0.3925\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.5161 - accuracy: 0.7534 - val_loss: 1.6120 - val_accuracy: 0.4953\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.5751 - accuracy: 0.7732 - val_loss: 0.8451 - val_accuracy: 0.6449\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.3558 - accuracy: 0.8463 - val_loss: 0.4692 - val_accuracy: 0.8411\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.3078 - accuracy: 0.8761 - val_loss: 0.4264 - val_accuracy: 0.8411\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.2850 - accuracy: 0.8699 - val_loss: 0.3658 - val_accuracy: 0.8972\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 37s 1s/step - loss: 0.2428 - accuracy: 0.8996 - val_loss: 0.3752 - val_accuracy: 0.8598\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.3249 - accuracy: 0.8451 - val_loss: 0.2842 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.3469 - accuracy: 0.8525 - val_loss: 0.2350 - val_accuracy: 0.9159\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.3399 - accuracy: 0.8587 - val_loss: 0.2991 - val_accuracy: 0.8692\n",
      "4/4 [==============================] - 1s 172ms/step\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Custom decision threshold\n",
    "OVERROLL_THRESHOLD = 0.4\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Load and crop images\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "\n",
    "# Convert cropped images into a format suitable for training\n",
    "cropped_images_array = np.array([cv2.resize(img, (224, 224)) for img in original_images]) / 255.0\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create a data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Compute confusion matrices for each class\n",
    "confusion_matrices = []\n",
    "\n",
    "# Initialize metrics dictionary for precision, recall, F1 score, and accuracy\n",
    "class_metrics = {'precision': {}, 'recall': {}, 'f1-score': {}, 'accuracy': {}}\n",
    "\n",
    "# K-Fold Cross-Validation loop\n",
    "for train_index, val_index in stratified_k_fold.split(cropped_images_array, encoded_labels):\n",
    "    \n",
    "    X_train, X_val = cropped_images_array[train_index], cropped_images_array[val_index]\n",
    "    y_train, y_val = categorical_labels[train_index], categorical_labels[val_index]\n",
    "        \n",
    "    # Apply SMOTE to the training data only\n",
    "    smote = SMOTE()\n",
    "    X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_reshaped, y_train)\n",
    "    X_train_smote = X_train_smote.reshape(X_train_smote.shape[0], 224, 224, 3)\n",
    "    \n",
    "    # Create data generator for the training set\n",
    "    train_generator = train_datagen.flow(X_train_smote, y_train_smote,batch_size=BATCH_SIZE, seed=seed)\n",
    "    \n",
    "    # Define the CNN model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define TensorBoard callback\n",
    "    log_dir = \"logs/fit/CNN with SMOTE\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Fit the model using the data generator\n",
    "    history = model.fit(train_generator, validation_data=(X_val, y_val), epochs=10, callbacks=[tensorboard_callback],\n",
    "                         class_weight=class_weight_dict)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "    # Apply custom decision threshold\n",
    "    y_pred_binary = (y_pred > OVERROLL_THRESHOLD).astype(int)\n",
    "    \n",
    "    # Compute confusion matrix and add to the list\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "    confusion_matrices.append(cnf_matrix)\n",
    "\n",
    "    # Calculate and accumulate the metrics\n",
    "    report = classification_report(y_true, y_pred_classes, output_dict=True, zero_division=1)\n",
    "    \n",
    "    for lbl in label_encoder.classes_:\n",
    "        class_idx = label_encoder.transform([lbl])[0]\n",
    "        class_metrics['precision'][lbl] = class_metrics['precision'].get(lbl, []) + [report[str(class_idx)]['precision']]\n",
    "        class_metrics['recall'][lbl] = class_metrics['recall'].get(lbl, []) + [report[str(class_idx)]['recall']]\n",
    "        class_metrics['f1-score'][lbl] = class_metrics['f1-score'].get(lbl, []) + [report[str(class_idx)]['f1-score']]\n",
    "        class_metrics['accuracy'][lbl] = class_metrics['accuracy'].get(lbl, []) + [accuracy_score(y_true[y_true==class_idx],\n",
    "                                                                                                   y_pred_classes[y_true==class_idx])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the metrics\n",
    "for metric, class_data in class_metrics.items():\n",
    "    for lbl, values in class_data.items():\n",
    "        class_metrics[metric][lbl] = np.mean(values)\n",
    "\n",
    "# Visualizing the metrics\n",
    "for metric_name in ['f1-score', 'accuracy']:\n",
    "    plot_metrics(class_metrics[metric_name], metric_name)\n",
    "\n",
    "# Sample three images from each class/label\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for lbl in label_encoder.classes_:\n",
    "    class_idx = label_encoder.transform([lbl])[0]\n",
    "    indices = np.where(np.array(y_true) == class_idx)[0][:3]  # Sample three images per class\n",
    "    sample_images.extend(X_test[indices])\n",
    "    sample_labels.extend([lbl] * 3)\n",
    "\n",
    "# Resize sampled images to match the model's input shape\n",
    "sample_images_resized = [cv2.resize(img, (224, 224)) for img in sample_images]\n",
    "\n",
    "# Generate predictions for the sampled images with the same thresholds as during validation\n",
    "sample_predictions = model.predict(np.array(sample_images_resized))\n",
    "\n",
    "# Apply custom decision thresholds\n",
    "brown_streak_index = label_encoder.transform(['brown_streak'])[0]  # Get the index for the 'brown_streak' class\n",
    "sample_predictions_binary = np.zeros_like(sample_predictions)\n",
    "sample_predictions_binary[sample_predictions > OVERROLL_THRESHOLD] = 1  \n",
    "sample_predictions_binary[(sample_predictions[:, brown_streak_index] > OVERROLL_THRESHOLD), brown_streak_index] = 1  \n",
    "\n",
    "# Convert to class labels based on custom decision thresholds\n",
    "sample_predictions_classes = np.argmax(sample_predictions_binary, axis=1)\n",
    "\n",
    "# Decode the true and predicted labels to their original string labels\n",
    "decoded_true_labels = label_encoder.inverse_transform([label_encoder.transform([lbl])[0] for lbl in sample_labels])\n",
    "decoded_predicted_labels = label_encoder.inverse_transform(sample_predictions_classes)\n",
    "\n",
    "# Plot the sampled images along with their true and predicted labels\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"True: {decoded_true_labels[i]}\\nPred: {decoded_predicted_labels[i]}\", fontsize=10)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These enhancements suggest that combining data augmentation, SMOTE, and adjusting the decision threshold has improved the model's ability to classify the different leaf conditions, with particular improvements in the mosaic disease and healthy classes; brown streak also showed improvement in F1-score and accuracy, though it remains a more challenging class to classify accurately compared to the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The brown streak disease has only 50 image samples, so its class's decision threshold is reduced further to 0.35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cassava\\brown_streak\n",
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 32s 1s/step - loss: 1.2221 - accuracy: 0.5622 - val_loss: 0.6935 - val_accuracy: 0.7222\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.6594 - accuracy: 0.7500 - val_loss: 1.1093 - val_accuracy: 0.7130\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.4821 - accuracy: 0.7935 - val_loss: 0.5115 - val_accuracy: 0.8333\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.5163 - accuracy: 0.7774 - val_loss: 0.3429 - val_accuracy: 0.8426\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.3599 - accuracy: 0.8483 - val_loss: 0.4459 - val_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.3440 - accuracy: 0.8495 - val_loss: 0.3223 - val_accuracy: 0.8796\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.3206 - accuracy: 0.8682 - val_loss: 0.3355 - val_accuracy: 0.8796\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.3227 - accuracy: 0.8806 - val_loss: 0.7105 - val_accuracy: 0.7963\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.3239 - accuracy: 0.8520 - val_loss: 0.5958 - val_accuracy: 0.7870\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.2964 - accuracy: 0.8843 - val_loss: 0.2759 - val_accuracy: 0.8981\n",
      "4/4 [==============================] - 1s 190ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 40s 1s/step - loss: 1.9635 - accuracy: 0.5489 - val_loss: 0.6857 - val_accuracy: 0.7009\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.7183 - accuracy: 0.6791 - val_loss: 0.5430 - val_accuracy: 0.7477\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.5310 - accuracy: 0.7732 - val_loss: 1.3331 - val_accuracy: 0.5981\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.4189 - accuracy: 0.8178 - val_loss: 0.4406 - val_accuracy: 0.8411\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.3966 - accuracy: 0.8129 - val_loss: 0.3353 - val_accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.3505 - accuracy: 0.8463 - val_loss: 0.4955 - val_accuracy: 0.8131\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.4081 - accuracy: 0.8228 - val_loss: 0.3431 - val_accuracy: 0.8692\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.3270 - accuracy: 0.8587 - val_loss: 0.4373 - val_accuracy: 0.8505\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.3425 - accuracy: 0.8662 - val_loss: 0.3351 - val_accuracy: 0.8879\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.3020 - accuracy: 0.8476 - val_loss: 0.3364 - val_accuracy: 0.8879\n",
      "4/4 [==============================] - 1s 158ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 31s 1s/step - loss: 2.0103 - accuracy: 0.4895 - val_loss: 2.1659 - val_accuracy: 0.3084\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.6769 - accuracy: 0.6939 - val_loss: 1.1200 - val_accuracy: 0.5701\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.4090 - accuracy: 0.8129 - val_loss: 0.5813 - val_accuracy: 0.8318\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.7219 - accuracy: 0.7658 - val_loss: 1.3262 - val_accuracy: 0.6449\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.8650 - accuracy: 0.6084 - val_loss: 0.5477 - val_accuracy: 0.7944\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 25s 954ms/step - loss: 0.6024 - accuracy: 0.7286 - val_loss: 0.8759 - val_accuracy: 0.6822\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 25s 975ms/step - loss: 0.3647 - accuracy: 0.8352 - val_loss: 0.4888 - val_accuracy: 0.8505\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 24s 935ms/step - loss: 0.2882 - accuracy: 0.8674 - val_loss: 1.4647 - val_accuracy: 0.6636\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.3466 - accuracy: 0.8426 - val_loss: 0.5450 - val_accuracy: 0.8224\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.3341 - accuracy: 0.8600 - val_loss: 0.5166 - val_accuracy: 0.8318\n",
      "4/4 [==============================] - 1s 144ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 46s 2s/step - loss: 2.0278 - accuracy: 0.5638 - val_loss: 1.8841 - val_accuracy: 0.3178\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 45s 2s/step - loss: 0.6996 - accuracy: 0.7088 - val_loss: 0.3558 - val_accuracy: 0.8785\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.5396 - accuracy: 0.7670 - val_loss: 0.3138 - val_accuracy: 0.8879\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.3465 - accuracy: 0.8426 - val_loss: 0.4244 - val_accuracy: 0.8505\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.3444 - accuracy: 0.8451 - val_loss: 0.4779 - val_accuracy: 0.8598\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.4058 - accuracy: 0.8154 - val_loss: 1.0161 - val_accuracy: 0.6262\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.4389 - accuracy: 0.8141 - val_loss: 0.6069 - val_accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.4042 - accuracy: 0.8315 - val_loss: 0.5279 - val_accuracy: 0.8318\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.3811 - accuracy: 0.8439 - val_loss: 0.3760 - val_accuracy: 0.8505\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.3001 - accuracy: 0.8736 - val_loss: 0.3601 - val_accuracy: 0.8879\n",
      "4/4 [==============================] - 1s 210ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 39s 1s/step - loss: 2.4242 - accuracy: 0.4263 - val_loss: 1.3345 - val_accuracy: 0.3364\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 38s 1s/step - loss: 0.9009 - accuracy: 0.5998 - val_loss: 0.7173 - val_accuracy: 0.7757\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 39s 2s/step - loss: 0.5672 - accuracy: 0.7224 - val_loss: 1.3393 - val_accuracy: 0.4579\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.4749 - accuracy: 0.7831 - val_loss: 0.5886 - val_accuracy: 0.8411\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 46s 2s/step - loss: 0.4725 - accuracy: 0.8042 - val_loss: 0.4003 - val_accuracy: 0.8318\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 39s 1s/step - loss: 0.3634 - accuracy: 0.8364 - val_loss: 0.3726 - val_accuracy: 0.8411\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 42s 2s/step - loss: 0.4719 - accuracy: 0.8240 - val_loss: 0.4262 - val_accuracy: 0.8224\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 45s 2s/step - loss: 0.3241 - accuracy: 0.8612 - val_loss: 0.2874 - val_accuracy: 0.8785\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 52s 2s/step - loss: 0.2653 - accuracy: 0.8823 - val_loss: 0.3887 - val_accuracy: 0.8598\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 46s 2s/step - loss: 0.2857 - accuracy: 0.8773 - val_loss: 0.5005 - val_accuracy: 0.8785\n",
      "4/4 [==============================] - 1s 261ms/step\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Custom decision threshold\n",
    "OVERROLL_THRESHOLD = 0.4\n",
    "BROWN_STREAK_THRESHOLD = 0.35\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Load and crop images\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "\n",
    "# Convert cropped images into a format suitable for training\n",
    "cropped_images_array = np.array([cv2.resize(img, (224, 224)) for img in original_images]) / 255.0\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create a data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Compute confusion matrices for each class\n",
    "confusion_matrices = []\n",
    "\n",
    "# Initialize metrics dictionary for precision, recall, F1 score, and accuracy\n",
    "class_metrics = {'precision': {}, 'recall': {}, 'f1-score': {}, 'accuracy': {}}\n",
    "\n",
    "# K-Fold Cross-Validation loop\n",
    "for train_index, val_index in stratified_k_fold.split(cropped_images_array, encoded_labels):\n",
    "    \n",
    "    X_train, X_val = cropped_images_array[train_index], cropped_images_array[val_index]\n",
    "    y_train, y_val = categorical_labels[train_index], categorical_labels[val_index]    \n",
    "    \n",
    "    # Apply SMOTE to the training data only\n",
    "    smote = SMOTE()\n",
    "    X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_reshaped, y_train)\n",
    "    X_train_smote = X_train_smote.reshape(X_train_smote.shape[0], 224, 224, 3)\n",
    "    \n",
    "    # Create data generator for the training set\n",
    "    train_generator = train_datagen.flow(X_train_smote, y_train_smote,batch_size=BATCH_SIZE, seed=seed)\n",
    "    \n",
    "    # Define the CNN model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define TensorBoard callback\n",
    "    log_dir = \"logs/fit/smote and threshold for brown streak\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Fit the model using the data generator\n",
    "    history = model.fit(train_generator, validation_data=(X_val, y_val), epochs=10, callbacks=[tensorboard_callback], \n",
    "                        class_weight=class_weight_dict)\n",
    "        \n",
    "    # Model evaluation and metrics calculation\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Apply custom decision thresholds\n",
    "    brown_streak_index = label_encoder.transform(['brown_streak'])[0]  # Get the index for the 'brown_streak' class\n",
    "    y_pred_binary = np.zeros_like(y_pred)\n",
    "    y_pred_binary[y_pred > OVERROLL_THRESHOLD] = 1\n",
    "    y_pred_binary[(y_pred[:, brown_streak_index] > BROWN_STREAK_THRESHOLD), brown_streak_index] = 1  # Special threshold for brown_streak\n",
    "    \n",
    "    # Convert to class labels based on custom decision thresholds\n",
    "    y_pred_classes = np.argmax(y_pred_binary, axis=1)\n",
    "            \n",
    "    # Compute confusion matrix and add to the list\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "    confusion_matrices.append(cnf_matrix)\n",
    "\n",
    "    # Calculate and accumulate the metrics\n",
    "    report = classification_report(y_true, y_pred_classes, output_dict=True, zero_division=1)\n",
    "    \n",
    "    for lbl in label_encoder.classes_:\n",
    "        class_idx = label_encoder.transform([lbl])[0]\n",
    "        class_metrics['precision'][lbl] = class_metrics['precision'].get(lbl, []) + [report[str(class_idx)]['precision']]\n",
    "        class_metrics['recall'][lbl] = class_metrics['recall'].get(lbl, []) + [report[str(class_idx)]['recall']]\n",
    "        class_metrics['f1-score'][lbl] = class_metrics['f1-score'].get(lbl, []) + [report[str(class_idx)]['f1-score']]\n",
    "        class_metrics['accuracy'][lbl] = class_metrics['accuracy'].get(lbl, []) + [accuracy_score(y_true[y_true==class_idx],\n",
    "                                                                                                   y_pred_classes[y_true==class_idx])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the metrics\n",
    "for metric, class_data in class_metrics.items():\n",
    "    for lbl, values in class_data.items():\n",
    "        class_metrics[metric][lbl] = np.mean(values)\n",
    "\n",
    "# Visualizing the metrics\n",
    "for metric_name in ['f1-score', 'accuracy']:\n",
    "    plot_metrics(class_metrics[metric_name], metric_name)\n",
    "\n",
    "# Sample three images from each class/label\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for lbl in label_encoder.classes_:\n",
    "    class_idx = label_encoder.transform([lbl])[0]\n",
    "    indices = np.where(np.array(y_true) == class_idx)[0][:3]  # Sample three images per class\n",
    "    sample_images.extend(X_test[indices])\n",
    "    sample_labels.extend([lbl] * 3)\n",
    "\n",
    "# Resize sampled images to match the model's input shape\n",
    "sample_images_resized = [cv2.resize(img, (224, 224)) for img in sample_images]\n",
    "\n",
    "# Generate predictions for the sampled images with the same thresholds as during validation\n",
    "sample_predictions = model.predict(np.array(sample_images_resized))\n",
    "\n",
    "# Apply custom decision thresholds: 0.7 for all classes and 0.35 for brown_streak\n",
    "brown_streak_index = label_encoder.transform(['brown_streak'])[0]  # Get the index for the 'brown_streak' class\n",
    "sample_predictions_binary = np.zeros_like(sample_predictions)\n",
    "sample_predictions_binary[sample_predictions > OVERROLL_THRESHOLD] = 1  # Higher threshold for other two classes to 0.7\n",
    "sample_predictions_binary[(sample_predictions[:, brown_streak_index] > BROWN_STREAK_THRESHOLD), brown_streak_index] = 1  # Lower threshold for 'brown_streak' class to 0.4\n",
    "\n",
    "# Convert to class labels based on custom decision thresholds\n",
    "sample_predictions_classes = np.argmax(sample_predictions_binary, axis=1)\n",
    "\n",
    "# Decode the true and predicted labels to their original string labels\n",
    "decoded_true_labels = label_encoder.inverse_transform([label_encoder.transform([lbl])[0] for lbl in sample_labels])\n",
    "decoded_predicted_labels = label_encoder.inverse_transform(sample_predictions_classes)\n",
    "\n",
    "# Plot the sampled images along with their true and predicted labels\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"True: {decoded_true_labels[i]}\\nPred: {decoded_predicted_labels[i]}\", fontsize=10)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the reduced threshold for brown streak, there was a noticeable improvement in mosaic disease and healthy classes regarding F1 score and accuracy, with both classes achieving higher scores. However, the brown streak still presented difficulties, with a lower F1-score and accuracy, suggesting that this class remains challenging for classification even with these various adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch to ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN is an improvement upon the SMOTE approach and is applied to address the extreme class imbalance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cassava\\brown_streak\n",
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 42s 2s/step - loss: 1.5934 - accuracy: 0.4353 - val_loss: 1.3049 - val_accuracy: 0.3704\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 37s 1s/step - loss: 0.6797 - accuracy: 0.6771 - val_loss: 2.3998 - val_accuracy: 0.4444\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 37s 1s/step - loss: 0.8218 - accuracy: 0.7231 - val_loss: 0.7263 - val_accuracy: 0.7870\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 42s 2s/step - loss: 0.6556 - accuracy: 0.7316 - val_loss: 0.4320 - val_accuracy: 0.8241\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 44s 2s/step - loss: 0.5201 - accuracy: 0.7666 - val_loss: 0.5880 - val_accuracy: 0.7407\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 42s 2s/step - loss: 0.4281 - accuracy: 0.8198 - val_loss: 0.7353 - val_accuracy: 0.7315\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.5470 - accuracy: 0.7630 - val_loss: 0.7569 - val_accuracy: 0.8241\n",
      "4/4 [==============================] - 1s 250ms/step\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.6841 - accuracy: 0.4353 - val_loss: 0.9684 - val_accuracy: 0.3084\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 27s 1s/step - loss: 0.8524 - accuracy: 0.6018 - val_loss: 0.7136 - val_accuracy: 0.6449\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 25s 971ms/step - loss: 0.6763 - accuracy: 0.7106 - val_loss: 0.7957 - val_accuracy: 0.7196\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 25s 972ms/step - loss: 0.5265 - accuracy: 0.7490 - val_loss: 0.4011 - val_accuracy: 0.8411\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 25s 980ms/step - loss: 0.4578 - accuracy: 0.8169 - val_loss: 0.4283 - val_accuracy: 0.8411\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 24s 939ms/step - loss: 0.4613 - accuracy: 0.8041 - val_loss: 0.5220 - val_accuracy: 0.7850\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 24s 945ms/step - loss: 0.3854 - accuracy: 0.8054 - val_loss: 0.4386 - val_accuracy: 0.8131\n",
      "4/4 [==============================] - 1s 157ms/step\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 26s 976ms/step - loss: 1.5784 - accuracy: 0.4084 - val_loss: 1.7626 - val_accuracy: 0.3364\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 26s 978ms/step - loss: 0.7265 - accuracy: 0.6542 - val_loss: 1.1819 - val_accuracy: 0.5607\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 26s 979ms/step - loss: 0.5880 - accuracy: 0.7434 - val_loss: 0.9356 - val_accuracy: 0.6542\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 26s 993ms/step - loss: 0.4730 - accuracy: 0.8036 - val_loss: 0.5293 - val_accuracy: 0.8224\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.4091 - accuracy: 0.8289 - val_loss: 0.4313 - val_accuracy: 0.8131\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.3344 - accuracy: 0.8494 - val_loss: 0.4537 - val_accuracy: 0.8318\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 25s 959ms/step - loss: 0.3442 - accuracy: 0.8458 - val_loss: 0.4802 - val_accuracy: 0.8505\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.3832 - accuracy: 0.8289 - val_loss: 0.6913 - val_accuracy: 0.7196\n",
      "4/4 [==============================] - 1s 153ms/step\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 27s 1s/step - loss: 1.6554 - accuracy: 0.3795 - val_loss: 1.0266 - val_accuracy: 0.3458\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 25s 951ms/step - loss: 0.9789 - accuracy: 0.5747 - val_loss: 1.2320 - val_accuracy: 0.4953\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 25s 943ms/step - loss: 0.6248 - accuracy: 0.7398 - val_loss: 0.3872 - val_accuracy: 0.8411\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.4568 - accuracy: 0.7964 - val_loss: 0.6798 - val_accuracy: 0.7570\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 26s 1s/step - loss: 0.4525 - accuracy: 0.8084 - val_loss: 0.4312 - val_accuracy: 0.8598\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 24s 901ms/step - loss: 0.4934 - accuracy: 0.7759 - val_loss: 0.4138 - val_accuracy: 0.7944\n",
      "4/4 [==============================] - 1s 158ms/step\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 25s 940ms/step - loss: 1.4545 - accuracy: 0.4451 - val_loss: 1.2352 - val_accuracy: 0.3458\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 31s 1s/step - loss: 0.7877 - accuracy: 0.6490 - val_loss: 1.0269 - val_accuracy: 0.5421\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.4706 - accuracy: 0.7768 - val_loss: 0.9313 - val_accuracy: 0.6636\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 26s 1s/step - loss: 0.4053 - accuracy: 0.8166 - val_loss: 0.4395 - val_accuracy: 0.8224\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 24s 926ms/step - loss: 0.3629 - accuracy: 0.8215 - val_loss: 0.5130 - val_accuracy: 0.8037\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 24s 916ms/step - loss: 0.3431 - accuracy: 0.8323 - val_loss: 0.6841 - val_accuracy: 0.8131\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 25s 947ms/step - loss: 0.3515 - accuracy: 0.8384 - val_loss: 0.9268 - val_accuracy: 0.7009\n",
      "4/4 [==============================] - 1s 165ms/step\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Custom decision threshold\n",
    "OVERROLL_THRESHOLD = 0.4\n",
    "BROWN_STREAK_THRESHOLD = 0.35\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Load and crop images\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "\n",
    "# Convert cropped images into a format suitable for training\n",
    "cropped_images_array = np.array([cv2.resize(img, (224, 224)) for img in original_images]) / 255.0\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create a data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Compute confusion matrices for each class\n",
    "confusion_matrices = []\n",
    "\n",
    "# Initialize metrics dictionary for precision, recall, F1 score, and accuracy\n",
    "class_metrics = {'precision': {}, 'recall': {}, 'f1-score': {}, 'accuracy': {}}\n",
    "\n",
    "# K-Fold Cross-Validation loop\n",
    "for train_index, val_index in stratified_k_fold.split(cropped_images_array, encoded_labels):\n",
    "    \n",
    "    X_train, X_val = cropped_images_array[train_index], cropped_images_array[val_index]\n",
    "    y_train, y_val = categorical_labels[train_index], categorical_labels[val_index]    \n",
    "    \n",
    "    # Apply ADASYN to the training data only\n",
    "    adasyn = ADASYN()\n",
    "    X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_reshaped, y_train)\n",
    "    X_train_adasyn = X_train_adasyn.reshape(X_train_adasyn.shape[0], 224, 224, 3)\n",
    "    \n",
    "    # Create data generator for the training set\n",
    "    train_generator = train_datagen.flow(X_train_adasyn, y_train_adasyn,batch_size=BATCH_SIZE, seed=seed)\n",
    "    \n",
    "    # Define the enhanced CNN model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.7),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define TensorBoard callback\n",
    "    log_dir = \"logs/fit/ADASYN\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Fit the model using the data generator\n",
    "    history = model.fit(train_generator, validation_data=(X_val, y_val), epochs=25, \n",
    "                        callbacks=[tensorboard_callback,early_stopping], class_weight=class_weight_dict)\n",
    "        \n",
    "    # Model evaluation and metrics calculation\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Apply custom decision thresholds\n",
    "    brown_streak_index = label_encoder.transform(['brown_streak'])[0]  # Get the index for the 'brown_streak' class\n",
    "    y_pred_binary = np.zeros_like(y_pred)\n",
    "    y_pred_binary[y_pred > OVERROLL_THRESHOLD] = 1\n",
    "    y_pred_binary[(y_pred[:, brown_streak_index] > BROWN_STREAK_THRESHOLD), brown_streak_index] = 1  # Special threshold for brown_streak\n",
    "    \n",
    "    # Convert to class labels based on custom decision thresholds\n",
    "    y_pred_classes = np.argmax(y_pred_binary, axis=1)\n",
    "            \n",
    "    # Compute confusion matrix and add to the list\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "    confusion_matrices.append(cnf_matrix)\n",
    "\n",
    "    # Calculate and accumulate the metrics\n",
    "    report = classification_report(y_true, y_pred_classes, output_dict=True, zero_division=1)\n",
    "    \n",
    "    for lbl in label_encoder.classes_:\n",
    "        class_idx = label_encoder.transform([lbl])[0]\n",
    "        class_metrics['precision'][lbl] = class_metrics['precision'].get(lbl, []) + [report[str(class_idx)]['precision']]\n",
    "        class_metrics['recall'][lbl] = class_metrics['recall'].get(lbl, []) + [report[str(class_idx)]['recall']]\n",
    "        class_metrics['f1-score'][lbl] = class_metrics['f1-score'].get(lbl, []) + [report[str(class_idx)]['f1-score']]\n",
    "        class_metrics['accuracy'][lbl] = class_metrics['accuracy'].get(lbl, []) + [accuracy_score(y_true[y_true==class_idx],\n",
    "                                                                                                   y_pred_classes[y_true==class_idx])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the metrics\n",
    "for metric, class_data in class_metrics.items():\n",
    "    for lbl, values in class_data.items():\n",
    "        class_metrics[metric][lbl] = np.mean(values)\n",
    "\n",
    "# Visualizing the metrics\n",
    "for metric_name in ['f1-score', 'accuracy']:\n",
    "    plot_metrics(class_metrics[metric_name], metric_name)\n",
    "\n",
    "# Sample three images from each class/label\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for lbl in label_encoder.classes_:\n",
    "    class_idx = label_encoder.transform([lbl])[0]\n",
    "    indices = np.where(np.array(y_true) == class_idx)[0][:3]  # Sample three images per class\n",
    "    sample_images.extend(X_test[indices])\n",
    "    sample_labels.extend([lbl] * 3)\n",
    "\n",
    "# Resize sampled images to match the model's input shape\n",
    "sample_images_resized = [cv2.resize(img, (224, 224)) for img in sample_images]\n",
    "\n",
    "# Generate predictions for the sampled images with the same thresholds as during validation\n",
    "sample_predictions = model.predict(np.array(sample_images_resized))\n",
    "\n",
    "# Apply custom decision thresholds\n",
    "brown_streak_index = label_encoder.transform(['brown_streak'])[0]  # Get the index for the 'brown_streak' class\n",
    "sample_predictions_binary = np.zeros_like(sample_predictions)\n",
    "sample_predictions_binary[sample_predictions > OVERROLL_THRESHOLD] = 1 \n",
    "sample_predictions_binary[(sample_predictions[:, brown_streak_index] > BROWN_STREAK_THRESHOLD), brown_streak_index] = 1   # Special threshold for brown_streak\n",
    "\n",
    "# Convert to class labels based on custom decision thresholds\n",
    "sample_predictions_classes = np.argmax(sample_predictions_binary, axis=1)\n",
    "\n",
    "# Decode the true and predicted labels to their original string labels\n",
    "decoded_true_labels = label_encoder.inverse_transform([label_encoder.transform([lbl])[0] for lbl in sample_labels])\n",
    "decoded_predicted_labels = label_encoder.inverse_transform(sample_predictions_classes)\n",
    "\n",
    "# Plot the sampled images along with their true and predicted labels\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"True: {decoded_true_labels[i]}\\nPred: {decoded_predicted_labels[i]}\", fontsize=10)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These adjustments improved the model's ability to classify mosaic disease and healthy conditions, with brown streak still a more challenging class. However, it showed a modest improvement in F1 score and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DenseNet121 as a feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing transfer learning to improve the model's ability to extract features and efficient training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cassava\\brown_streak\n",
      "Loading images from Cassava\\healthy1\n",
      "Loading images from Cassava\\mosaic_disease1\n",
      "Loaded labels: ['brown_streak' 'healthy1' 'mosaic_disease1']\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 61s 2s/step - loss: 1.2222 - accuracy: 0.5550 - val_loss: 0.5245 - val_accuracy: 0.7963\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 52s 2s/step - loss: 0.5694 - accuracy: 0.7666 - val_loss: 0.7030 - val_accuracy: 0.6389\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 53s 2s/step - loss: 0.4206 - accuracy: 0.8138 - val_loss: 0.3548 - val_accuracy: 0.8426\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 53s 2s/step - loss: 0.3338 - accuracy: 0.8549 - val_loss: 0.4342 - val_accuracy: 0.7963\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.2564 - accuracy: 0.8888 - val_loss: 0.2956 - val_accuracy: 0.8796\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 54s 2s/step - loss: 0.2505 - accuracy: 0.8888 - val_loss: 0.2427 - val_accuracy: 0.8981\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.2519 - accuracy: 0.9045 - val_loss: 0.2594 - val_accuracy: 0.8889\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 46s 2s/step - loss: 0.1761 - accuracy: 0.9274 - val_loss: 0.2975 - val_accuracy: 0.8796\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 54s 2s/step - loss: 0.1575 - accuracy: 0.9323 - val_loss: 0.2218 - val_accuracy: 0.9074\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.1780 - accuracy: 0.9238 - val_loss: 0.1805 - val_accuracy: 0.9167\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.1814 - accuracy: 0.9141 - val_loss: 0.2052 - val_accuracy: 0.8981\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.1382 - accuracy: 0.9407 - val_loss: 0.1255 - val_accuracy: 0.9444\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.1492 - accuracy: 0.9359 - val_loss: 0.2713 - val_accuracy: 0.8889\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.1330 - accuracy: 0.9371 - val_loss: 0.2047 - val_accuracy: 0.8981\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 58s 2s/step - loss: 0.1104 - accuracy: 0.9516 - val_loss: 0.1700 - val_accuracy: 0.9167\n",
      "4/4 [==============================] - 6s 1s/step\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 50s 2s/step - loss: 1.5879 - accuracy: 0.5109 - val_loss: 1.0023 - val_accuracy: 0.4486\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.6003 - accuracy: 0.7298 - val_loss: 1.0147 - val_accuracy: 0.5047\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.4408 - accuracy: 0.8079 - val_loss: 0.3639 - val_accuracy: 0.8318\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.3341 - accuracy: 0.8540 - val_loss: 0.3728 - val_accuracy: 0.8411\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2761 - accuracy: 0.8771 - val_loss: 0.3412 - val_accuracy: 0.8598\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.2442 - accuracy: 0.8988 - val_loss: 0.3189 - val_accuracy: 0.8692\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.2408 - accuracy: 0.8848 - val_loss: 0.3838 - val_accuracy: 0.8131\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1999 - accuracy: 0.9014 - val_loss: 0.2994 - val_accuracy: 0.8879\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2072 - accuracy: 0.9078 - val_loss: 0.3495 - val_accuracy: 0.8598\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1546 - accuracy: 0.9270 - val_loss: 0.3039 - val_accuracy: 0.8972\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 50s 2s/step - loss: 0.1659 - accuracy: 0.9181 - val_loss: 0.3893 - val_accuracy: 0.8505\n",
      "4/4 [==============================] - 6s 1s/step\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 60s 2s/step - loss: 1.1355 - accuracy: 0.5843 - val_loss: 0.7123 - val_accuracy: 0.5888\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.5188 - accuracy: 0.7602 - val_loss: 0.3381 - val_accuracy: 0.8879\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.3848 - accuracy: 0.8410 - val_loss: 0.4578 - val_accuracy: 0.7757\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.2694 - accuracy: 0.8663 - val_loss: 0.3255 - val_accuracy: 0.8879\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.2928 - accuracy: 0.8699 - val_loss: 0.3729 - val_accuracy: 0.8411\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 57s 2s/step - loss: 0.2130 - accuracy: 0.9048 - val_loss: 0.1897 - val_accuracy: 0.9346\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 53s 2s/step - loss: 0.2074 - accuracy: 0.9193 - val_loss: 0.3476 - val_accuracy: 0.8505\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 54s 2s/step - loss: 0.1826 - accuracy: 0.9072 - val_loss: 0.2955 - val_accuracy: 0.8785\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.1647 - accuracy: 0.9386 - val_loss: 0.3652 - val_accuracy: 0.8411\n",
      "4/4 [==============================] - 7s 1s/step\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 56s 2s/step - loss: 1.2379 - accuracy: 0.5627 - val_loss: 1.3767 - val_accuracy: 0.3458\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.5379 - accuracy: 0.7675 - val_loss: 0.3991 - val_accuracy: 0.7850\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.4470 - accuracy: 0.8145 - val_loss: 0.6104 - val_accuracy: 0.7103\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.3314 - accuracy: 0.8506 - val_loss: 0.4162 - val_accuracy: 0.7664\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.2809 - accuracy: 0.8711 - val_loss: 0.3503 - val_accuracy: 0.7944\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.2477 - accuracy: 0.9036 - val_loss: 0.4509 - val_accuracy: 0.7570\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.1872 - accuracy: 0.9145 - val_loss: 0.4001 - val_accuracy: 0.7850\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.2343 - accuracy: 0.9108 - val_loss: 0.4088 - val_accuracy: 0.7757\n",
      "4/4 [==============================] - 6s 1s/step\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 55s 2s/step - loss: 1.5515 - accuracy: 0.5115 - val_loss: 0.6087 - val_accuracy: 0.7290\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.6120 - accuracy: 0.7587 - val_loss: 0.5020 - val_accuracy: 0.7477\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.4127 - accuracy: 0.8480 - val_loss: 0.7320 - val_accuracy: 0.6449\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 52s 2s/step - loss: 0.3438 - accuracy: 0.8649 - val_loss: 0.2871 - val_accuracy: 0.8785\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 53s 2s/step - loss: 0.3070 - accuracy: 0.8758 - val_loss: 0.2692 - val_accuracy: 0.8692\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 53s 2s/step - loss: 0.2535 - accuracy: 0.9023 - val_loss: 0.2020 - val_accuracy: 0.8972\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 52s 2s/step - loss: 0.2436 - accuracy: 0.8999 - val_loss: 0.1834 - val_accuracy: 0.9252\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.2081 - accuracy: 0.9119 - val_loss: 0.1872 - val_accuracy: 0.9252\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.2395 - accuracy: 0.9144 - val_loss: 0.1623 - val_accuracy: 0.9439\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.1891 - accuracy: 0.9095 - val_loss: 0.2090 - val_accuracy: 0.9439\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.1542 - accuracy: 0.9300 - val_loss: 0.1881 - val_accuracy: 0.9346\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.1361 - accuracy: 0.9373 - val_loss: 0.1270 - val_accuracy: 0.9533\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.1481 - accuracy: 0.9324 - val_loss: 0.1081 - val_accuracy: 0.9626\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.1203 - accuracy: 0.9493 - val_loss: 0.1116 - val_accuracy: 0.9439\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.1226 - accuracy: 0.9566 - val_loss: 0.1236 - val_accuracy: 0.9533\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.1235 - accuracy: 0.9373 - val_loss: 0.1601 - val_accuracy: 0.9533\n",
      "4/4 [==============================] - 6s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Custom decision threshold\n",
    "OVERROLL_THRESHOLD = 0.7\n",
    "BROWN_STREAK_THRESHOLD = 0.4\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Load and crop images\n",
    "folders = ['./Cassava/brown_streak/', './Cassava/healthy1', './Cassava/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "\n",
    "# Convert cropped images into a format suitable for training\n",
    "cropped_images_array = np.array([cv2.resize(img, (224, 224)) for img in original_images]) / 255.0\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Create a data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Compute confusion matrices for each class\n",
    "confusion_matrices = []\n",
    "\n",
    "# Initialize metrics dictionary for precision, recall, F1 score, and accuracy\n",
    "class_metrics = {'precision': {}, 'recall': {}, 'f1-score': {}, 'accuracy': {}}\n",
    "\n",
    "# Initialize base model\n",
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "fold_count = 1\n",
    "\n",
    "# K-Fold Cross-Validation loop\n",
    "for train_index, val_index in stratified_k_fold.split(cropped_images_array, encoded_labels):\n",
    "    \n",
    "    X_train, X_val = cropped_images_array[train_index], cropped_images_array[val_index]\n",
    "    y_train, y_val = categorical_labels[train_index], categorical_labels[val_index]    \n",
    "    \n",
    "    # Apply ADASYN to the training data only\n",
    "    adasyn = ADASYN()\n",
    "    X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_reshaped, y_train)\n",
    "    X_train_adasyn = X_train_adasyn.reshape(X_train_adasyn.shape[0], 224, 224, 3)\n",
    "    \n",
    "    # Create data generator for the training set\n",
    "    train_generator = train_datagen.flow(X_train_adasyn, y_train_adasyn,batch_size=BATCH_SIZE, seed=seed)\n",
    "    \n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add new layers on top\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = ReLU()(x)  \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = ReLU()(x)  \n",
    "    x = Dropout(0.3)(x) \n",
    "    predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define TensorBoard callback\n",
    "    log_dir = \"logs/fit/Densenet121 and ADASYN\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Fit the model using the data generator\n",
    "    history = model.fit(train_generator, validation_data=(X_val, y_val), epochs=25, callbacks=[tensorboard_callback,\n",
    "                                                                                               early_stopping], \n",
    "                                                                                               class_weight=class_weight_dict)\n",
    "\n",
    "    model.save(f\"dense121-model_{fold_count}.h5\")\n",
    "\n",
    "    fold_count = fold_count + 1\n",
    "        \n",
    "    # Model evaluation and metrics calculation\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Apply custom decision thresholds\n",
    "    brown_streak_index = label_encoder.transform(['brown_streak'])[0]  # Get the index for the 'brown_streak' class\n",
    "    y_pred_binary = np.zeros_like(y_pred)\n",
    "    y_pred_binary[y_pred > OVERROLL_THRESHOLD] = 1 \n",
    "    y_pred_binary[(y_pred[:, brown_streak_index] > BROWN_STREAK_THRESHOLD), brown_streak_index] = 1   # Special threshold for brown_streak\n",
    "    \n",
    "    # Convert to class labels based on custom decision thresholds\n",
    "    y_pred_classes = np.argmax(y_pred_binary, axis=1)\n",
    "            \n",
    "    # Compute confusion matrix and add to the list\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "    confusion_matrices.append(cnf_matrix)\n",
    "\n",
    "    # Calculate and accumulate the metrics\n",
    "    report = classification_report(y_true, y_pred_classes, output_dict=True, zero_division=1)\n",
    "    \n",
    "    for lbl in label_encoder.classes_:\n",
    "        class_idx = label_encoder.transform([lbl])[0]\n",
    "        class_metrics['precision'][lbl] = class_metrics['precision'].get(lbl, []) + [report[str(class_idx)]['precision']]\n",
    "        class_metrics['recall'][lbl] = class_metrics['recall'].get(lbl, []) + [report[str(class_idx)]['recall']]\n",
    "        class_metrics['f1-score'][lbl] = class_metrics['f1-score'].get(lbl, []) + [report[str(class_idx)]['f1-score']]\n",
    "        class_metrics['accuracy'][lbl] = class_metrics['accuracy'].get(lbl, []) + [accuracy_score(y_true[y_true==class_idx],\n",
    "                                                                                                   y_pred_classes[y_true==class_idx])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging the metrics\n",
    "for metric, class_data in class_metrics.items():\n",
    "    for lbl, values in class_data.items():\n",
    "        class_metrics[metric][lbl] = np.mean(values)\n",
    "\n",
    "# Visualizing the metrics\n",
    "for metric_name in ['f1-score', 'accuracy']:\n",
    "    plot_metrics(class_metrics[metric_name], metric_name)\n",
    "\n",
    "# Sample three images from each class/label\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for lbl in label_encoder.classes_:\n",
    "    class_idx = label_encoder.transform([lbl])[0]\n",
    "    indices = np.where(np.array(y_true) == class_idx)[0][:3]  # Sample three images per class\n",
    "    sample_images.extend(X_test[indices])\n",
    "    sample_labels.extend([lbl] * 3)\n",
    "\n",
    "# Resize sampled images to match the model's input shape\n",
    "sample_images_resized = [cv2.resize(img, (224, 224)) for img in sample_images]\n",
    "\n",
    "# Generate predictions for the sampled images with the same thresholds as during validation\n",
    "sample_predictions = model.predict(np.array(sample_images_resized))\n",
    "\n",
    "# Apply custom decision thresholds\n",
    "brown_streak_index = label_encoder.transform(['brown_streak'])[0]  # Get the index for the 'brown_streak' class\n",
    "sample_predictions_binary = np.zeros_like(sample_predictions)\n",
    "sample_predictions_binary[sample_predictions > OVERROLL_THRESHOLD] = 1  \n",
    "sample_predictions_binary[(sample_predictions[:, brown_streak_index] > BROWN_STREAK_THRESHOLD), brown_streak_index] = 1   # Special threshold for brown_streak\n",
    "\n",
    "# Convert to class labels based on custom decision thresholds\n",
    "sample_predictions_classes = np.argmax(sample_predictions_binary, axis=1)\n",
    "\n",
    "# Decode the true and predicted labels to their original string labels\n",
    "decoded_true_labels = label_encoder.inverse_transform([label_encoder.transform([lbl])[0] for lbl in sample_labels])\n",
    "decoded_predicted_labels = label_encoder.inverse_transform(sample_predictions_classes)\n",
    "\n",
    "# Plot the sampled images along with their true and predicted labels\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(len(sample_images)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"True: {decoded_true_labels[i]}\\nPred: {decoded_predicted_labels[i]}\", fontsize=10)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model displayed remarkable accuracy and precision, especially in identifying mosaic disease and brown streak. These findings demonstrate the effectiveness of these strategies in optimizing the use of training data and enhancing the overall model performance for cassava leaf disease classification. With the small and limited image data of brown streak disease, it must be noted that additional data for training may be needed to improve its F1 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is tested against 107 images from dataverse.harvard.edu https://doi.org/10.7910/DVN/T4RB0B covering the three leaf conditions for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Define class names (folder names)\n",
    "class_names = ['brown_streak', 'healthy1', 'mosaic_disease1']\n",
    "\n",
    "def plot_metrics(metrics, metric_name):\n",
    "    # Extract the desired metric for each class\n",
    "    values = [metrics[label][metric_name] for label in class_names]\n",
    "\n",
    "    # Calculate the mean of the metric\n",
    "    mean_metric = np.mean(values)\n",
    "\n",
    "    # Generate colors from viridis colormap within the range [4/4.5, 4.5/7]\n",
    "    colormap = cm.viridis(np.linspace(4/4.5, 4.5/7, len(class_names)))\n",
    "\n",
    "    # Create a bar chart to visualize the metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(class_names, values, color=colormap)\n",
    "    plt.axhline(mean_metric, color='red', linestyle='--', label=f'Mean {metric_name}: {mean_metric:.2f}')\n",
    "    plt.xlabel('Leaf Condition')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'{metric_name} by Leaf Condition')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Custom decision threshold\n",
    "OVERROLL_THRESHOLD = 0.7\n",
    "BROWN_STREAK_THRESHOLD = 0.4\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Load and crop images\n",
    "folders = ['./Cassava Test/brown_streak/', './Cassava Test/healthy1', './Cassava Test/mosaic_disease1']\n",
    "original_images, labels = load_images_and_labels(folders)\n",
    "\n",
    "# Convert cropped images into a format suitable for testing\n",
    "cropped_images_array = np.array([cv2.resize(img, (224, 224)) for img in original_images]) / 255.0\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = model.predict(cropped_images_array)\n",
    "\n",
    "# Apply custom decision thresholds to test predictions\n",
    "test_predictions_binary = np.zeros_like(test_predictions)\n",
    "test_predictions_binary[test_predictions > OVERROLL_THRESHOLD] = 1\n",
    "test_predictions_binary[(test_predictions[:, brown_streak_index] > BROWN_STREAK_THRESHOLD), brown_streak_index] = 1\n",
    "\n",
    "# Convert to class labels based on custom decision thresholds\n",
    "test_predictions_classes = np.argmax(test_predictions_binary, axis=1)\n",
    "\n",
    "# Decode the true labels\n",
    "decoded_test_labels = label_encoder.inverse_transform(encoded_labels)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(encoded_labels, test_predictions_classes)\n",
    "\n",
    "# Generate the classification report as a dictionary\n",
    "test_classification_report = classification_report(encoded_labels, test_predictions_classes, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Print the classification report\n",
    "print(test_classification_report)\n",
    "\n",
    "# Visualize the metrics\n",
    "plot_metrics(test_classification_report, 'f1-score')\n",
    "\n",
    "# Calculate accuracy separately\n",
    "accuracy = accuracy_score(encoded_labels, test_predictions_classes)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Sample and visualize predictions\n",
    "sample_test_indices = np.random.choice(len(original_images), 9, replace=False)\n",
    "\n",
    "# Resize sampled test images to match the model's input shape\n",
    "sample_test_images_resized = [cv2.resize(original_images[i], (224, 224)) for i in sample_test_indices]\n",
    "\n",
    "# Sample predictions based on custom thresholds\n",
    "sample_test_predictions = test_predictions_binary[sample_test_indices]\n",
    "sample_test_predictions_classes = np.argmax(sample_test_predictions, axis=1)\n",
    "\n",
    "# Decode true and predicted labels\n",
    "sample_true_labels = [decoded_test_labels[i] for i in sample_test_indices]\n",
    "sample_predicted_labels = label_encoder.inverse_transform(sample_test_predictions_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that the model performs exceptionally well classifying healthy leaves with high precision, recall, and F1-score. However, the model's performance is relatively low for brown streak disease, as reflected in lower precision, recall, and F1-score values. The mosaic disease classification falls in between the two. The overall model accuracy is 0.76, indicating a reasonable ability to classify the different leaf conditions.\n",
    "\n",
    "Improvement areas include using ROC AUC to comprehensively evaluate the model's classification thresholds and possibly attaining more significant samples, especially the underrepresented classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
